Supported byBy Bruce HorovitzA new partnership among two prominent Israeli venture capital funds, a handful of major private-sector companies and the city’s economic growth development enterprise is hoping to turn New York City into the nation’s leading center for yet one more major industry: cybersecurity.Cyber NYC, as the project is called, is among the nation’s most ambitious cybersecurity initiatives, which over the next decade could transform New York City into a global leader of cybersecurity innovation and job creation.The multiyear project would simultaneously create a Global Cyber Center in Chelsea, a cybersecurity innovation hub in the SoHo neighborhood of Manhattan and an academic cybepartnership with area colleges, such as Columbia University, New York University and City University of New York. At the same time, major corporations such as Goldman Sachs, Mastercard and PricewaterhouseCoopers also are participating in advisory roles or to assist with the project’s training and hiring.“We are at a seminal moment in the trajectory of the cybersecurity industry,” said James Patchett, president and chief executive of the New York City Economic Development Corporation, which is spearheading the Cyber NYC initiative, including assembling and leading public-private partnerships and developing and overseeing six programs to grow New York’s cyberindustry and expand the work force.“Making New York City the epicenter of cybersecurity makes complete sense because New York City is where all the customers are,” Mr. Patchett said.Cyber NYC will initially be funded by about $70 million in private investments, including from the two Israeli firms: Jerusalem Venture Partners, a venture capital fund; and SOSA, a corporate innovation specialist, among others Another $30 million is coming from the city. Its goal: to create 10,000 local cybersecurity jobs over the next decade as part of Mayor de Blasio’s New York Works Plan.Two new cybersecurity centers in separate locations will work in tandem to anchor this project. In SoHo, a 50,000-square-foot cybersecurity investment hub will support cybersecurity start-ups in New York City. In Chelsea, the 15,000-square-foot Global Cyber Center will bring together investors, corporations and start-ups and serve as a virtual testing ground to run simulations. Both are expected to be completed before the end of 2019.According to the New York City Economic Development Corporation, cybersecurity already is a $1 billion-plus industry in New York, with more than 100 companies and 6,000 employees as of 2017.Those numbers are expected to grow as the city continues to attract new technology-related companies. The highest-profile is Amazon, which selected New York’s Long Island City as one of its East Coast headquarters. “We’re the logical place for this to be located,” Mr. Patchett said.The real driver behind a project like Cyber NYC is the nation’s urgent need for improved cybersecurity at all levels of corporate and government operations. Nearly 60 million Americans have been affected by identity theft, according to a 2018 online survey by The Harris Poll, an increase from 15 million in 2017.Cybersecurity attacks have become so common that experts worry about the onset of “cyberfatigue” as consumers begun to shrug off their impact. A corporate cyberattack takes place every 40 seconds via ransomware across the globe, reported Cybersecurity Ventures, a research specialist in the global cybereconomy. That figure is expected to be every 14 seconds by next year. Cybercrimes, Cybersecurity Ventures also noted, are predicted to cause $6 trillion in damages by 2021, an increase from $3 trillion in 2015.Despite the clear need for cybersecurity upgrades and improvements, not everyone is convinced that a project like Cyber NYC is the right solution.“This sounds like a huge marketing pitch,” said Bruce Schneier, a cybersecurity expert who has written 13 books on the topic. “I’ve worked in this field forever, and I’ve never even heard the term cybersecurity hub.” Such skepticism doesn’t really bother Erel Margalit, founder and chairman of Jerusalem Venture Partners, which is overseeing the creation of the cybersecurity investment hub in SoHo.“Come and see what we already have done in Israel,” Mr. Margalit said, in response to Mr. Schneier’s skepticism. Jerusalem Venture Partners has raised over $1.3 billion to create and finance more than 130 companies — more than one-third of them in cybersecurity, including CyberArk, which is one of Israel’s largest cybersecurity companies (Israel is second to the U.S. in terms of overall investment in cybersecurity firms). “If someone wants to call this a marketing ploy, O.K. The storytelling part is important. When you tell people a story, they listen.”Mr. Margalit, who as a former member of Israel’s legislative body, the Knesset, led its cybersecurity task force. Mr. Margalit earned his Ph.D. at Columbia and was living in New York City during 9/11. He says that his company will oversee much of the business end of the venture. “Most innovation occurs when the two disciplines meet: investors and cybersecurity experts,” he said.Equally invested in Cyber NYC’s success is Uzi Scheffer, chief executive of SOSA, which has offices in Tel Aviv and New York. The company mostly focuses on protecting major financial companies from cyberattacks. While SOSA already has been operating out of another New York location for about 18 months, it is building the Global Cyber Center in Chelsea and plans to move into it in 2019.“The Global Cyber Center will expose New York’s largest players to the best cybersecurity solutions out there,” said Mr. Scheffer.Mr. Scheffer said a global cybersecurity hub doesn’t really exist anywhere yet. “It’s about seizing the opportunity rather than taking it away from someone else,” said Scheffer, whose firm, like Jerusalem Venture Partners, secured its partnership with Cyber NYC through a competitive bidding process.There’s also a serious academic element to the overall cybersecurity partnership, which involves the participation of virtually every major academic institution in New York City. “Whether or not this leads to New York becoming the single, cybersecurity hub of the world is a story that will be played out over the next 15 years,” said Orin Herskowitz, senior vice president of Intellectual Property and Tech Transfer for Columbia University. In the meantime, he says, the combined efforts will train and link local university students with substantive cybersecurity jobs in NYC.“There is a real chance this will become a catalytic event,” Mr. Herskowitz said.There’s even a so-called Cybersecurity Boot Camp planned, where the city’s Fullstack Academy and CUNY LaGuardia Community College plan to educate and place more than 1,000 students in high-paying cybersecurity jobs over the first three years of the program. Program development for the boot camp has begun with the first session scheduled to take place in spring 2019.Until now, all of the major cybersecurity stakeholders in New York City have been physically and operationally separated, said Satish Rao, associate director of physical sciences licensing at Columbia, who helps to support cybersecurity start-ups. But with Cyber NYC, he said, “a coalition of stakeholders is coming together.”One such stakeholder is Mark Gazit, chief executive of ThetaRay, an Israeli financial cybersecurity specialty company, which opened a temporary New York office at another location 18 months ago, but will be ultimately be housed in the SoHo building early next year. ThetaRay will start with about 15 to 20 employees at the location, but plans to have more than 100 within several years, Gazit said.“Few people come to a bank branch and use a gun to steal money,” he said. Today, the thief is far more likely to be behind a server in some remote country, stealing money without any physical access to the bank, he says. His company, which aims to prevent the spread of this cybercrime, works with such clients as General Electric.To be a cybercriminal is the highest-paying, low-risk job in the world, Mr. Gazit said. “Nobody knows who you are, and you can disappear without a trace,” he says.His and other cybersecurity companies hope to make New York City the center of halting cybercrime. There is no better location than New York, said Mr. Gazit, because New York is where the talent is and where the financial giants are headquartered.“At the end of the day,” Mr. Gazit said, “we have to make sure the good guys win. ”Because of editing errors, earlier versions of picture captions with this article misidentified a building in SoHo that is part of the Cyber NYC initiative. It is a future cybersecurity innovation hub, not the future Global Cyber Center, which will be in Chelsea. One of the captions also misspelled the surnames of two people involved with the hub. They are Tali Rabin, not Raben, and Gil Becker, not Beker.

Supported byBy Paulette PerhachA stunning statistic is reverberating in cybersecurity: An estimated 3.5 million cybersecurity jobs will be available but unfilled by 2021, according to predictions from Cybersecurity Ventures and other experts.“It’s scary. Our power grid, our cars, our everyday devices — basically everything is online and able to be attacked,” said Georgia Weidman, author of “Penetration Testing: A Hands-On Introduction to Hacking.” Ms. Weidman is the founder of two cybersecurity companies, Bulb Security, where she is chief executive, and Shevirah, where she is chief technology officer. Shevirah specializes in security for mobile devices.“It would certainly cause mass destruction if our power grid went down or our water pumps started going haywire or our dams decided to open all their sluices,” she said. “That’s actually something that could happen.”According to a report released this year by the Identity Theft Resource Center, the number of data breaches tracked in the United States in 2017 hit a high of more than 1,500, up almost 45 percent over 2016. In one incident this year, the data of 29 million Facebook users was stolen.In response to the sheer number of new digital gates that might be left open, employers and educators have had to become more creative in finding people to guard them.They need penetration testers to simulate attacks to find and fix vulnerabilities that could be exploited by a real attacker.They need malware analysts to find out what malicious programs do so they can protect from the attacks.They need security researchers to discover new vulnerabilities in applications and other products — before the thieves do — so they can be fixed. They need security architects to make sure all the best practices are being followed.According to the chief economist for LinkedIn, Guy Berger, there was a shortage as of September of 11,000 people with cybersecurity skills in the San Francisco Bay Area, 5,000 in New York and almost 4,000 in Seattle, the areas with the largest concentration of need. LinkedIn regularly issues work-force reports based on its analysis of jobs data in the United States.Some major corporations have openly taken to hiring hackers to help protect them. An extreme example is Kevin Mitnick, who hacked into corporations, landed on the F.B.I. Most Wanted Fugitives list, went to jail for five years, but is now a security consultant to Fortune 500 companies and governments. As he says on his website about hackers, “It takes one to know one.”Many companies are also putting less emphasis on the need for a college degree to qualify for a cybersecurity job, Ms. Weidman said. With an undergraduate degree in mathematics from Mary Baldwin College in Staunton, Va., and a master’s in computer science from James Madison University in Harrisonburg, Va., Ms. Weidman said she had seen how much hands-on experience really mattered in the cyberfield. That insight came early when she participated in the National Collegiate Cyber Defense Competition as a student.The competition, which began in 2005, is held at colleges across the country and designed to test student teams’ abilities to detect and respond to outside threats and to protect services such as mail servers and web servers. The sponsors include high-tech companies like the defense contractor Raytheon and IBM, but also retailers like Walmart and transportation companies like Uber.Recalling the difference between theoretical learning in college and hands-on experience, Ms. Weidman said she could do a lot of math about computer networking, “but could I actually manage a network at a company? Absolutely not.”The people who were in community colleges would “wipe the floor with those of us at universities, because community colleges really were focused on how to do these things,” she said. “I think that people at the university level are starting to realize that we need more hands-on skills in cybersecurity, as well as just the theory.”With that in mind, colleges and universities are changing their curriculums. Ms. Weidman is working with the Tulane School of Professional Advancement in New Orleans to build an online class for its Applied Computing Systems &amp; Technology degree program.At New York University, the Center for Cybersecurity has been operating for 20 years and graduates about 50 students annually. But this year, it created an online master’s program to help make the training more affordable in hopes of attracting more people to the field.Students in cybersecurity get a 75 percent discount, so the master’s degree costs about $15,000, compared with about $60,000 for the traditional on-campus program. The online program enrolled 125 students in September and hopes to have 1,000 students annually within three or four years.“Nationally, we graduate twice the number of psychology majors as opposed to engineers,” said Nasir Memon, professor and associate dean for online learning at the N.Y.U. Tandon School of Engineering. “We graduate as many park rangers as compared to computer scientists.”Students frequently graduate in fields that lack opportunity for long-term careers, he said. If they want to switch to computer science in traditional programs, they can face daunting barriers, like multiple semesters of catch-up courses and a requirement to take the Graduate Record Examination.“So one of the things we did is start a bridge program, where we say, we don’t care what you did in your undergrad; you could have done physics, anthropology, anything, just come on in,” Professor Memon said.The welcome the school extends is in the form of an intense, four-month online program of computer science courses with a price of $1,500. If students pass, they are eligible for the full program.This year, 230 students were accepted into the bridge program, 22 percent of them women. That number compares with 11 percent of women in the cybersecurity force over all, according to a 2017 report by the Center for Cyber Safety and Education and the Executive Women’s Forum on Information Security, Risk Management &amp; Privacy.Shamla Naidoo, global chief information security officer for IBM, has had success reaching out to mothers returning to work, as well as to veterans, to find potential cybersecurity workers.“We’ve been talking about this for the last few years,” Ms. Naidoo said. “The first year, I spent a lot of time worrying about it. After that I thought, there’s no point in worrying about it, I’m going to have to go act, and I’m going to have to act in a nontraditional way. Posting a job description and hoping people are going to show up and apply to the job wasn’t working because the people just didn’t exist. So rather than trying to hire the skills and knowing they’re not as easily available, let’s create the skills internally.”She created a system open to hiring people who have little or no experience, and, in many cases, even skills, in cybersecurity, with the understanding that they will come in, join a more experienced team and learn on the job. They are formed into teams of five to seven people solving one problem at a time, with the new employees teaming with more experienced security experts to watch.Many skills from other industries are transferable to the cybersecurity field. Cybersecurity experts need to be able to communicate policies to, as Ms. Naidoo put it, “increase the cybersecurity I.Q.” of an entire organization. For example, people from a finance background might be able to educate their co-workers in accounting about cyberrisk.She’s grown her team by about 25 percent over the last year with developers, consultants and research professionals. She said being more flexible in hiring, and hiring outside of the normal pipeline, had evened out some of the inequities in the field — like a relative dearth of minorities and women.“To solve the skills shortage, we have to hire people who have the right aptitude, who have the right attitude, people who are curious, are willing to learn,” Ms. Naidoo said. “Outside of that, I have very few other criteria. I’m opening the aperture for where we look. I’m trying to hire in nontraditional places, nontraditional groups of people, and so I don’t expect them to have the skills or the experience that we need. I will hire people wherever I can find them.”Michael Doran, 38, was a police officer in St. Louis for almost 10 years before going into cybersecurity.“I quickly found out a lot of the older detectives were not doing a lot of the computer crimes,” he said. “I saw my opening there to make a niche for myself.”After learning about the field of digital forensics, he took free, online courses through the National White Collar Crime Center. He then decided to get another bachelor’s degree and a master’s degree online in computer forensics and intelligence. He studied at Utica College from home while working full time.He went to the cybercrimes unit as a forensic digital examiner within the St. Louis police department’s cybercrime unit. But it didn’t take long for the private industry to scoop him up.“It was an offer I couldn’t refuse,” he said, speaking of more than doubling his salary to near six figures. “I took that chance, and I haven’t looked back since.”He’s now a senior security consultant within the enterprise incident management team for Optiv, a cybersecurity company, where he performs digital forensics and interacts with clients.More C-suite executives are filling their own skills gaps when it comes to cybersecurity, said Eric Rosenbach, co-director of the Belfer Center for Science and International Affairs at Harvard Kennedy School and former chief of staff at the Defense Department.He runs an online class for working, senior-level executives “who are only now seeing how seriously they need to take it because they’ve seen so many other C.E.O.s get fired for major breaches,” said Mr. Rosenbach.Offered at least six times a year, the classes educate 300 to 400 people each term. He says executives need to know how to minimize the legal, financial and public relations risks before an attack occurs.Beyond the particular needs of firms in the cybersecurity arena, there is also a skills gap in the larger population that needs to be addressed, Mr. Rosenbach said.“I’m surprised, even at Harvard, how few of the students here know very basic stuff about cyberhygiene, two-factor authentication, things like that, that people should be doing to protect themselves,” he said.“One thing I don’t think people appreciate as much is that cyber is about human issues, it’s about training people not to do dumb things like click on spear-phishing links, holding people accountable. There’s a lot of human leadership involved in trying to improve cybersecurity.”

Supported byAnother ViewBy Craig A. NewmanGet the DealBook newsletter to make sense of major business and policy headlines — and the power-brokers who shape them.__________Shareholders haven’t been successful in holding companies accountable for data breaches.That changed in the first month of 2019.The former officers and directors of Yahoo agreed to pay $29 million to settle charges that they breached their fiduciary duties in their handling of customer data during a series of cyberattacks from 2013 until 2016. Three billion Yahoo user accounts were compromised in the attacks. The settlement ended three so-called derivative lawsuits filed in Delaware and California against the company’s former leadership team and board, including Marissa Mayer, Yahoo’s former chief executive. Insurance coverage will pick up the tab.The settlement, approved this month by a Superior Court judge in Santa Clara, Calif., marked the first time that shareholders have been awarded a monetary damages in a derivative lawsuit related to a data breach. There have been very few breach-related derivative lawsuits, and all had been dismissed by the courts or settled without a payment to the shareholders.A derivative lawsuit is a legal mechanism that gives the owners of a company — the shareholders — a way to hold corporate directors and management accountable for their actions. Shareholders file a claim on the company’s behalf, with any money recovered going to the corporation, not the individual shareholders, because the violation harmed only the organization.Under the Yahoo settlement, the lawyers walk away with about $11 million in fees and expenses, with the remaining $18 million paid to Yahoo, now called Altaba after Verizon acquired Yahoo’s internet business in 2017.A $29 million settlement might seem trivial for a company that has a market capitalization of $38 billion. But it signals that director and officer liability for cybersecurity oversight is entering new and potentially perilous territory. That is especially so in cases like Yahoo’s, in which shareholders allege egregious misconduct at the highest levels of an organization.Those allegations might explain why the Yahoo case was settled.Insurers don’t typically cough up tens of millions of dollars to settle derivative cases, which can be tough for shareholders to win. They must show that board members breached their fiduciary responsibilities by consciously disregarding their duties. The chief justice of the Delaware Supreme Court has called these claims “possibly the most difficult theory in corporation law upon which a plaintiff might hope to win a judgment.”The parties jointly told the court that the settlement was fair, in the best interest of all parties, and that a series of data security improvements have been worked out to minimize the chances that this will happen again. But the facts of the case most likely led the insurers to conclude that their exposure could be greater than the settlement.The reason is that the actions alleged in the lawsuit are outrageous. The nearly 120-page complaint — which is heavily redacted — reads at points more like a criminal indictment than a lawsuit. It accuses Yahoo’s former leaders of engaging in an elaborate, yearslong plot to cover up hacks going back to 2013 and conducting a “sham” investigation to “conceal the largest hacking incident in U.S. history.”Yahoo was a pioneer of the internet era, and the core of its business was providing ways for users to communicate with one another confidentially. Yet Yahoo failed miserably at this fundamental mission, according to the shareholders’ complaint. The expectations for consumer privacy and data security are far different for an internet company than a corner hardware store. The insurance carriers clearly understood this fact.The company’s settlement with the Securities and Exchange Commission in April provided further fodder to justify a settlement. The S.E.C. tagged Altaba with a $35 million penalty for failing to make a timely disclosure of the data breach, the commission’s first action for a cybersecurity disclosure violation.But it’s the details of the S.E.C. settlement that most likely proved the most troubling for the insurers. According to the S.E.C., “In late 2014, Yahoo had learned of a massive breach of its user database that resulted in the theft, unauthorized access or acquisition of hundreds of millions of its user’s personal data.” The agency further alleged that “Yahoo senior management and relevant legal staff did not properly assess the scope, business impact or legal implications of the breach” and “did not share information regarding the breach with Yahoo’s auditors or outside counsel.”Yahoo didn’t disclose the breach until September 2016, when it was negotiating the sale of its internet business to Verizon. Although the transaction was completed, the acquisition price was lowered by $350 million to $4.48 billion. That made for bad optics, a fact that the insurers probably recognized.Any company that figured it had little to fear from shareholders after a breach should now think twice. And in the meantime, this is definitely not the time to cut back insurance for officers and directors.Craig A. Newman is a partner and chair of the privacy practice at Patterson Belknap Webb &amp; Tyler, a New York law firm.

Supported byBy Ellen RosenThey have names like Notpetya, Samsam and perhaps the most cynically named WannaCry.These are just some of the most recent cyberattacks that have not only affected financial institutions, retailers and shipping companies but have also plagued manufacturers, like Merck &amp; Company, the pharmaceutical firm, and the snack company Mondelez International.Whether they come from ransomware, phishing or more arcane, highly sophisticated means, manufacturers are increasingly vulnerable to attacks that can shut down production and have ramifications throughout a supply chain.And it is not just the giants that get hacked; external threats can be agnostic, affecting manufacturers regardless of size.Thomas Siebel, the chairman and chief executive of C3, an artificial intelligence platform based in Redwood City, Calif., and the founder of Siebel Systems, puts it more bluntly, “Manufacturers are sloppy when it comes to cybersecurity.”The Taiwan Semiconductor Manufacturing Company learned that the hard way in August. A third-party vendor shipped software to the chip maker without pre-screening it. An engineer at Taiwan Semiconductor failed to scan the software, which was infected with the WannaCry ransomware, installed it and then connected it to the company’s operating system. The undetected virus then spread.The chief executive, C.C. Wei, speaking at a news conference at the time, rejected rumors of hacking. Instead, he acknowledged, it was “purely our own act of negligence.”But the company was lucky. A full recovery took only a few days, and while initially it seemed that third-quarter revenue would be off by 2 percent, Elizabeth Sun, a company spokeswoman, said in an email that the revenues did not suffer because Taiwan Semiconductor fulfilled some of the delayed orders, while “increases in demand in other areas” helped to offset the losses.Mondelez International and Merck suffered much more significant losses after the 2017 Notpetya attack, although they described them differently in filings.In its annual report for 2017 filed with the Securities and Exchange Commission, Mondelez stated that the “malware affected a significant portion of our global sales, distribution and financial networks.” The net revenue loss, the company said, was less than 1 percent of the company’s global net revenues of $25.9 billion. That still amounts to $103.6 million. In addition, the company incurred “incremental expenses of $84 million predominantly during the second half of 2017 as part of the recovery effort.”Merck, in its S.E.C. filings, stated that the attack “led to a disruption of its worldwide operations, including manufacturing, research and sales operations.” The fallout was significant: a $260 million loss in sales for 2017 with an expected additional loss for 2018 of $200 million. The total costs for expenses and remediation are $285 million, a net amount after insurance.Unlike Taiwan Semiconductor, neither Merck nor Mondelez described how the malware infected their operations. Boeing was said to have been attacked by WannaCry as well in March, but the company downplayed the hacking.While manufacturers weren’t traditionally at risk when hackers sought troves of individual data that could be sold for financial gain, motives have become more complex.Some using ransomware hope to extort money — sometimes in the form of cryptocurrencies — from companies whose systems are shut down. Others seek to steal intellectual property — a host of trade secrets including patent information and formulas, as well as blueprints and schematics.And last year’s NotPetya attack, which overall inflicted more than $1 billion in damage worldwide, was linked to the Russian military, the C.I.A. found.Irrespective of method or motive, the costs can be high, whether resulting from the ransom demands or the ensuing business disruption. Michael Tanenbaum an executive vice president of insurer Chubb, said attacks “have gone from being a nuisance to significant, with some demands exceeding seven figures.”Apart from the disruption to business, public companies that are hacked may also face scrutiny by the S.E.C. for failure to have a sufficient system of internal accounting controls, the agency warned in October.It doesn’t need to be that way, Mr. Siebel said. “It’s amazing what you can do with off-the-shelf cybersecurity products. Ninety percent of penetration can be stopped with fundamental practices that most people aren’t following, like employee training, two-factor authorization, changing passwords and fixing USB ports so they can’t download.”The vulnerabilities run from the mundane to the high-tech. Despite training and repeated warnings, employees still open phishing emails that can disrupt a company. Mr. Tanenbaum said that, according to a Chubb index, 50 percent of manufacturing losses in 2018 had resulted from phishing attacks or those known as “spear phishing,” which used some specific information to trick the recipient.“It means that individuals are clicking on links more readily in manufacturing than other industries,” he said. “This can cause real harm.”But there’s much more. A manufacturer’s exposure exists throughout a facility. Rare is the employee who punches a clock at the beginning of the day; instead, workers log in with passwords or biometrics.The vulnerabilities can be surprisingly simple and can emanate even from outdated equipment. John Reed Stark, president of John Reed Stark Consulting, a cybersecurity advisory firm, said a company, could, for example, have an old printer remain on a network even if it’s not used. A hacker could, through a phishing scheme, pick up the administrative passwords and then gain network access through the obsolete, but still connected printer. “And it can be difficult to know exactly what’s been exfiltrated — or stolen — from the network.”That was the vulnerability with the Notpetya attack — outdated Windows XP for which there hadn’t been updated security. While Microsoft did release a so-called patch to fix the problem, other outdated technologies still in use can result in exposure.So-called ntracontrol systems can connect aging as well as newer equipment, and frequently it’s difficult to shut some down without disrupting production. But if a manufacturer doesn’t take equipment offline to update security, there’s a risk that a ransomware attack, for example, could take an entire production line down, Mr. Tanenbaum explained.The growth of the Internet of Things — the direct connecting and communicating of disparate pieces of equipment — makes the potential for abuse even worse. While it is not yet considered an immediate concern, as hackers develop more sophisticated methods, the exposure could grow exponentially.“Manufacturing equipment is getting smarter, and we’re now moving into the information technology world in the manufacturing space,” said Manesh Patel, the senior vice president and chief information officer of the Sanmina Corporation, a Fortune 500 maker of optical, electronic and mechanical products based in San Jose, Calif. Many I.T. organizations, he added, focus on operations such as human resources, but still aren’t as well connected to the manufacturing side of the business.MForesight an independent, nonprofit manufacturing consortium focused on “technology, policy and the work force” has sounded the alarm and among other recommendations, suggests establishing organizations to “facilitate fault-free, anonymous sharing of incidents, threats, vulnerabilities, best practices and solutions.” The group also suggests developing a “comprehensive framework specifically for manufacturing supply chain cybersecurity, similar to existing frameworks on cybersecurity and cyberphysical security.”While comparing information seems at odds with companies that often compete, Mr. Patel, for one, stressed the importance of superior cybersecurity measures over a perceived competitive advantage.Mr. Patel, who said his company’s investment in cybersecurity measures has “increased 100 percent over the past three years,” also recommended segmenting, which means keeping systems on a network separate from each other. This can permit vendors to regularly update its equipment without having access to other parts of the system.Segmenting, he explained, secures a network so that it is not exposed to a potential breach from the vendor. It’s a relatively new area and if done incorrectly, can cause its own headaches. “We’re at the early stages of getting the grips of it.”Mr. Siebel has also asked known hackers to test his system by trying to infiltrate it. “We have hackers beating up our systems, and so far only one guy has gotten through, and we paid him a reward. He found a vulnerability, and we fixed it.Another approach is to adopt something called whitelisting. For years, Mr. Patel said, most companies had software that excluded known viruses, essentially blacklisting potential problems. But that was too reactive and sometimes exposed systems to unknown attackers. Now, he said, the better approach is to whitelist — that is specify approved software applications that are permitted to be active on a computer system. “It’s increasingly become one of the most important types of defenses.”Manufacturers also need to know the precautions that others — whether suppliers or customers — are taking, especially as they have increased access to equipment.“You are only as strong as your weakest link,” Mr. Stark said. “Hackers will find that weakest link and can break in and attack others in the supply chain. Companies are connected in ways that are extremely complex, and anyone in the supply chain can be vulnerable and could be the source of an attack.”

Supported byBy Daniel VictorHONG KONG — A lot of people don’t use computers. Most of them aren’t in charge of a nation’s cybersecurity.But one is. Japanese lawmakers were aghast on Wednesday when Yoshitaka Sakurada, 68, the minister who heads the government’s cybersecurity office, said during questioning in Parliament that he had no need for the devices, and appeared confused when asked basic technology questions.“I have been independently running my own business since I was 25 years old,” he said. When computer use is necessary, he said, “I order my employees or secretaries” to do it.“I don’t type on a computer,” he added.Asked by a lawmaker if nuclear power plants allowed the use of USB drives, a common technology widely considered to be a security risk, Mr. Sakurada did not seem to understand what they were.“I don’t know details well,” he said. “So how about having an expert answer your question if necessary, how’s that?”The comments were immediately criticized.“I can’t believe that a person who never used a computer is in charge of cybersecurity measures,” said Masato Imai, an opposition lawmaker.Even before his admission on Wednesday, Mr. Sakurada, who is also overseeing the 2020 Olympics in Tokyo, had occasionally attracted media coverage for head-scratching public comments. A week before his comments on cybersecurity, The Asahi Shimbun wrote that he showed a “knack for giving baffling replies.”His responses to questions about Olympic preparations “showed a stunning lack of understanding of basic issues concerning the event,” the newspaper wrote.He fumbled questions about how much the event would cost and whether North Korean officials would be attending, frequently turning to his aides for help, according to the newspaper. He said he had stumbled because he did not know the questions ahead of time.In 2016, he apologized after saying that so-called comfort women — Koreans who were abducted and forced to become sex slaves for the Imperial Japanese Army before and during World War II — were “prostitutes by occupation” and that people had been “heavily misled by propaganda work treating them as if they were victims.”His comments came a month after Japan and South Korea had officially settled a long-simmering dispute about reparations for the women, which remains a sore spot in relations between the two countries.The Japanese prime minister, Shinzo Abe, gave Mr. Sakurada oversight of cybersecurity and the Olympics and Paralympics last month in a cabinet shake-up.Hisako Ueno contributed reporting from Tokyo.

Supported byBy Stacy CowleyTwo years ago, IBM opened one of the nation’s first commercial cybersecurity ranges in Cambridge, Mass., to let companies practice responding to simulated cyberattacks. It describes the experience as “a game of Clue mixed with a Disney roller-coaster ride.”In a windowless bunker packed with a data center, wall-to-wall monitors, atmospheric controls, dozens of work stations and a functional TV studio, participants have about four hours to investigate and respond to a fictional data breach. It’s like an escape room for security nerds.The experience proved so popular — about 2,000 people, including chief executives and entire corporate boards, have played IBM’s game, which has an eight-month waiting list — that IBM decided to build a second range.But this time, it’s going mobile.The move is a reflection of the extent to which the threat of cyberattacks has captured the attention of organizations of all kinds, including the technology companies Facebook and Google, banks, military installations and those who run industrial control systems, like electricity and water providers. Tampering was a major issue in the election of President Trump, of course, and is cause for concern as the midterm elections approach.While companies are scrambling to get up to speed, they can’t always send an entire team away for a few days of training on how to spot and respond to a cyberattack.Starting Monday the company is introducing its mobile cyber command center, tucked into a heavily customized semitrailer truck. What IBM calls its “cyber tactical operations center” will make stops at college campuses and security-focused events before heading to Europe for a lengthy tour.Officially, the trailer is intended for cybersecurity education and as a mobile response unit. Unofficially, it’s also a playground packed with tech bling where geeks can experiment with ways to combat cyberattacks that have yet to be imagined.“People have put all kinds of cool things into trailers, but nobody has ever put a cyber command center into one before,” said Caleb Barlow, a vice president at IBM Security, where he leads the companys X-Force Threat Intelligence organization and created the Cambridge range.Touch screens displaying real-time threat monitoring — preferably with as many blinking charts and scary graphics as possible — are a must in any cyber war room. For the truck, IBM bought a 12-foot-long exterior screen that it said was one of the largest high-definition displays ever mounted to a vehicle.It also crammed in 20,000 feet of networking cable, two satellite dishes with cellular links, a generator-fueled power plant and a light tower with the intensity of 60 car headlights. Its data center, stuffed with server racks and multimedia controls, fits into a space the size of a large refrigerator.“This is toward the upper end of the most complicated trailers we’ve ever built,” said Mike Galvin, a sales manager for Featherlite, a manufacturer in Cresco, Iowa, that makes specialty trailers for emergency responders, mobile medical clinics and Nascar teams.On the road, the truck looks like any other shipping trailer hauling goods. But when it parks, it unfolds and triples its size. Beneath an extended canopy, IBM can unfurl a command post with 22 Mac-equipped work stations and a six-seat conference room.The main training room closely resembles IBM’s Cambridge range, with touch-screen monitors on three walls showing charts, video clips and forensic material like snippets of malicious computer code. From a tablet, IBM’s employees can adjust the room’s displays. A tap on the tablet’s “breaking news” button shifts the room’s lighting from a soothing blue to urgent red.“It helps us get the cortisol going,” Mr. Barlow said. “People react unconsciously to the visual cues.”Cyber ranges take their inspiration from the military. Just as soldiers train in simulated environments for the conditions they might face in battle, cyber defenders regularly practice on virtual networks. A growing number of companies participate in cyber war games and stage mock attacks to test their defenses.But few have the resources to build their own training arenas — a gap that security vendors are eager to fill. The companies Cyberbit and SimSpace make custom virtual ranges, and the military contractor Raytheon opened a 30,000-square-foot “live fire” range in 2015 for its customers.Sean McKee, a senior cyber threat manager for TD Bank, visited IBM’s Cambridge range this year and was intrigued enough to plan a two-day training exercise there in December for 40 TD Bank employees.The bank tests its crisis management plans at least once a year, incorporating everyone from front-line responders to its top executives, but its capabilities are less immersive than IBM’s, Mr. McKee said.In IBM’s training game, if an executive bungles a media interview, the range’s TV screens show the company’s stock price plunging as customers fire off angry Tweets. (Clips from Equifax’s widely criticized response to a data breach that exposed sensitive information on more than 145 million people are prominently featured in IBM’s presentation.)“People immediately get to see the results of their actions,” Mr. McKee said. “It gives them a sense that there are other forces at play here and the decisions you make in a moment of crisis are going to have a lasting impact on your organization.”Cybersecurity has become one of corporate America’s most pressing challenges, especially for companies that hold money or sensitive personal details. At least $445 billion was lost last year to cybercrime, a global economic study found, and an estimated 11 billion records have been stolen in data breaches, according to data compiled by the Privacy Rights Clearinghouse.Regulators, lawmakers and corporate customers have responded with more stringent requirements that companies improve their defenses and practice their crisis-response plans for handling significant attacks.“We’ve had growing demand from boards and C-suites, and it’s hard to get those people out to Cambridge,” Mr. Barlow said. “This is a way to bring training to them.”At the debut in Brooklyn, IBM plans to show off its new mobile system at a customer conference. Next week, it will head to the National Mall in Washington for a training event tied to efforts to prevent election hacking, and in November, it’s going to the Rochester Institute of Technology for a national penetration testing competition for college students.IBM is still figuring out exactly what it will do with its new toy. The truck is a fully functional command center, Mr. Barlow said. It could, in theory, be sent to large events — IBM works on cybersecurity for the United States Open and Wimbledon tennis tournaments — to handle real-time threat response.But its main purpose will be training. IBM plans to re-create its Cambridge mock-attack scenarios and build custom exercises for companies looking to test their skills.Mr. McKee, a former Canadian army officer, said that his bank, like many, had responded to escalating threats by increasing the pace and complexity of its training exercises. TD Bank’s session in December at the Cambridge range will mix technical challenges for the bank’s security incident response team with legal, public relations and privacy trials for its top executives.“I always run these exercises with the caveat that this is not a test,” he said. “A test is pass or fail. If you have certain areas where you go down in a flaming ball of fire, that’s a success. You found a critical vulnerability in your response.”

Supported byThe administration’s new policy of striking first at online attackers might invite cyberattacks, not deter them. By Josephine WolffMs. Wolff is an assistant professor at the Rochester Institute of Technology. At first glance, it would be easy to confuse the Trump administration’s new National Cyber Strategy with its predecessors: the Obama administration’s 2009 Cyberspace Policy Review and George W. Bush’s 2003 National Strategy to Secure Cyberspace. All three documents emphasize strikingly similar goals: the importance of hardening critical infrastructure, working with the private sector, securing government networks and establishing more robust partnerships for sharing information about online threats. Despite its similarities with previous administrations’ plans, however, the National Cyber Strategy represents an abrupt and reckless shift in how the United States government engages with adversaries online. Instead of continuing to focus on strengthening defensive technologies and minimizing the impact of security breaches, the Trump administration plans to ramp up offensive cyberoperations. The new goal: deter adversaries through pre-emptive cyberattacks and make other nations fear our retaliatory powers. The framework for this shift to an offense-first strategy is found in three recently announced pieces of policy. The first, the National Cyber Strategy, outlines a broad vision of how the administration plans to approach online issues and emphasizes the importance of imposing “swift, costly and transparent consequences” on online attackers. The second is the new Department of Defense cyber strategy, a more detailed plan for how the military will approach cybersecurity. It outlines a plan to “defend forward” by going after threats “before they reach their targets” and disrupting “malicious cyber activity at its source.” And the third is the classified National Security Presidential Memorandum 13, which makes it easier for the military to launch offensive cyberoperations by largely eliminating a lengthy interagency approval process put in place by the Obama administration.The idea of using offensive cyberattacks for defensive purposes is not a new one — discussions about the potential risks and rewards of “hacking back,” especially in the private sector, go back more than five years. But for the American government to embrace this strategy is a sharp change from the cautious, defense-oriented approach of the past decade. President Barack Obama was notably restrained in his authorization of offensive cyber missions. When deciding whether to use the Stuxnet worm to compromise uranium enrichment facilities in Iran in 2010 (his administration’s most famous use of offensive cyber capabilities), he reportedly expressed repeated concerns about the precedent it would set for other countries. The Obama administration’s forbearance and careful decision-making around cyberattack authorization aligns with the 2015 Department of Defense cyber strategy, which identified controlling the escalation of cyber conflicts as a key strategic goal. That goal is conspicuously absent from the Department of Defense’s new strategy. The Trump administration’s shift to an offensive approach is designed to escalate cyber conflicts, and that escalation could be dangerous. Not only will it detract resources and attention from the more pressing issues of defense and risk management, but it will also encourage the government to act recklessly in directing cyberattacks at targets before they can be certain of who those targets are and what they are doing. One of the advantages of the slow, unwieldy approval processes put into place by previous administrations is that they gave the government ample time to ascertain who was behind a cyberattack. That is not always easy to do: Many adversaries route cyberattacks through compromised third-party machines in other countries, such as university computer systems. Rushing to retaliate may make it more likely that the United States will lash out at the wrong target, which may invite new attacks rather than deter them. It could also lead to more attacks from existing adversaries like Russia and North Korea, from whom we already face substantial online threats. These countries have demonstrated their considerable online capabilities in cyberattacks directed at hospitals and power companies. If the United States pre-emptively attacks their servers and online infrastructure, it will only provoke greater and more damaging shows of force. And what these countries are capable of will be every bit as terrifying and harmful as what we can do. There is no evidence that pre-emptive cyberattacks will serve as effective deterrents to our adversaries in cyberspace. In fact, every time a country has initiated an unprompted cyberattack, it has invariably led to more conflict and has encouraged retaliatory breaches rather than deterring them. Nearly every major publicly known online intrusion that Russia or North Korea has perpetrated against the United States has had significant and unpleasant consequences. When North Korea compromised Sony Pictures in 2014 and stole the company’s data, it experienced a national disruption to its internet connectivity the following month. More recently, Russia has faced sanctions, indictments identifying their key online activities and personnel, and possibly covert cyber operations as punishment for a series of online intrusions and computer compromises. While nobody knows where these counterattacks originated, experts believe some of them came from the United States. Under the new attack-first policy, it’s likely that North Korea or Russia will retaliate against the United States in similar ways if threatened. For the United States, this is an especially risky approach given how much of our infrastructure — from energy distribution to financial systems to voting — is digitized and how vulnerable that dependence on computer networks makes us to cyberattacks.A smart national cyber strategy would focus on securing our computer systems, data and networks by allocating more money for their protection and by allocating more time and energy to regularly update, measure and test their security. It would charge the government with attacking its own servers and systems domestically to identify potential vulnerabilities before foreign adversaries have a chance to exploit them, rather than encouraging officials to strike out at overseas targets. And it would reserve the use of offensive cyber capabilities for situations that allow for careful consideration of the possible unintended consequences, narrow tailoring to a specific mission and contained, targeted damage.Ironically, the new national cyber strategy also charges the United States government with enhancing cyber stability “through norms of responsible state behavior.” As the rest of its policies make all too clear, this administration has already committed itself to irresponsible uses of cyber force that may serve to destabilize everyone’s online infrastructure, including our own.Josephine Wolff is an assistant professor at the Rochester Institute of Technology and the author of “You’ll See This Message When It Is Too Late: The Legal and Economic Aftermath of Cybersecurity Breaches.”Follow The New York Times Opinion section on Facebook and Twitter (@NYTopinion).

Supported byOp-Ed ContributorBy Nathaniel FickLast week, we learned that researchers had discovered two major flaws in microprocessors of nearly all the world’s computers. The revelation came on the heels of a distressing series of major hacks: In 2017, Yahoo revealed that all of its three billion accounts were compromised, WannaCry ransomware shut down hospitals across the globe, and an Equifax breach affected approximately 145.5 million consumers in the United States. The latest news about the computer security problems — whose names, “Spectre” and “Meltdown,” appropriately convey their seriousness — is just the latest evidence that true digital security remains out of our reach.But when these vulnerabilities are exposed and damaging attacks occur, there are few lasting repercussions. Almost without fail, stock prices bounce back, customers return, executives keep their jobs or exit with golden parachutes, and government mostly looks the other way. After the news of Equifax’s massive breach, for example, the company’s stock dropped roughly 35 percent. But it’s already recovered nearly half of its lost market value, and Fortune reported that the former chief executive officer Richard Smith retired with as much as $90 million in compensation. Resilience is one of the hallmarks of stable, mature markets, but something isn’t right here.The tepid consequences are part of a growing problem. From a corporate governance and accountability perspective, cybersecurity today is being treated like accounting was before the fallout from the Enron scandal inspired the Sarbanes-Oxley Act’s increased standards for corporate disclosures. With the privacy and personal data of hundreds of millions of people at risk, and especially now with the increasing ubiquity of connected devices in our lives, the security of digital assets is too important for that kind of treatment. We need to bolster a culture of responsibility around cybersecurity, combining stronger and more uniform corporate governance with a clearer government commitment to enact better defensive policies.A complex hack may not be a C.E.O.’s fault, but it is absolutely his or her responsibility. Investors and consumers need to demand more from the executives to whom they entrust their digital lives. The same holds true for government. Protection of the welfare and livelihood of its citizens is a foundational principle of government, and yet for more than a decade there has been very little consequence for nation-states and state-affiliated groups who’ve pilfered the intellectual property, and violated the personal privacy, of citizens and companies around the world.Strengthening a culture of responsibility will require changes by both companies and the government. Last year, the New York State Department of Financial Services took a promising step by implementing new data-security regulations for certain financial companies operating within the state. It includes rules for reporting cybersecurity events within 72 hours, annual proof-of-penetration tests, and, by 2020, third-party assessments — all designed to increase accountability and remove the fog of uncertainty that often surrounds breaches. The federal government would be wise to follow New York’s lead and implement similar laws on the federal level. Without federal action in this regard, increased regulation of cybersecurity practices will happen anyway, but in a fragmentary and disjointed way. More uniform regulations can help a more uniform standard to emerge, providing companies with the predictability and certainty they need in order to evaluate their risk management and security investments the right way.While more must be expected of companies, more should be expected of government as well. American businesses are under attack by our nation’s geopolitical adversaries, and by nonstate groups affiliated with them. Just imagine if American shipping companies were battling foreign navies, or if domestic airlines were fighting an adversary’s air force. This asymmetry locks the businesses into fights they cannot win.In its most dire scenario, the increasing velocity and severity of cyberattacks on American companies may encourage more firms to take matters into their own hands by “hacking back” against their attackers. This would open a Pandora’s box of ugly consequences. Even large Wall Street banks, spending hundreds of millions of dollars each year on security, cannot win against the Chinese or Russian militaries, so they escalate at their peril.But if private companies and individuals are not to fight back in self-defense, then their government must do a better job on their behalf.In short, the federal government must ensure that deterrence works in the digital domain. Cyberconflicts often pit the vast resources of nation-states against those of private companies. Businesses can only be reasonably expected to agree to increased cybersecurity regulation if they have confidence in the government to perform its basic function of protecting its citizens.Just as policy frameworks exist to respond to, and dissuade, physical attacks on Americans and their interests, foreign and domestic, so the government must deter adventurism in cyberspace. Notably, this doesn’t merely mean that one hack justifies another — rather, the full range of diplomatic, informational, economic and military options should be on the table. Failure to make such consequences clear and credible contributes to a fundamental failure of deterrence in cyberspace and exposes the United States government, American businesses, and individual citizens to many more such attacks in the future.Every business is now a digital business, and nearly every citizen is increasingly reliant on the connected world. We live in an era of mass targeted attacks where nation state-level resources are being directed against companies and private citizens, and until our security culture changes, we can expect to see more massive breaches throughout 2018 and beyond.Nathaniel Fick is the chief executive of Endgame, a cybersecurity software company.Follow The New York Times Opinion section on Facebook and Twitter (@NYTopinion), and sign up for the Opinion Today newsletter. 

Supported byBy Daisuke WakabayashiSAN FRANCISCO — A cybersecurity company said it had discovered a flaw in WhatsApp, the Facebook-owned messaging service with 1.5 billion users, that allows scammers to alter the content or change the identity of the sender of a previously delivered message.By creating a hacked version of the WhatsApp application, scammers can change a “quote” — a feature that allows people within a chat to display a past message and reply to it — to give the impression that someone sent a message they did not actually send, according to the company, Check Point Software Technologies.WhatsApp acknowledged that it was possible for someone to manipulate the quote feature, but the company disagreed that it was a flaw. WhatsApp said the system was working as it had intended, because the trade-offs to prevent such a deception by verifying every message on the platform would create an enormous privacy risk or bog down the service. The company said it worked to find and remove anyone using a fake WhatsApp application to spoof the service.“We carefully reviewed this issue and it’s the equivalent of altering an email,” Carl Woog, a spokesman for WhatsApp, said in a statement. What Check Point discovered had nothing to do with the security of WhatsApp’s so-called end-to-end encryption, which ensures only the sender and recipient can read messages, he said.WhatsApp has 1.5 billion users on its platform, making it the world’s most widely used messaging app. It has gained popularity for the simplicity and security of its service, providing encryption so that even the company does not know the content of its users’ messages. Facebook acquired WhatsApp in 2014 for $19 billion.But it has come under fire in recent months for the spread of misinformation on its platform. In India, false rumors about child kidnappers circulating through WhatsApp led to mob violence. In Brazil, false stories about deadly reactions to vaccines for the yellow fever spread over the messaging service.Mr. Woog of WhatsApp said the company was taking “the challenge of misinformation seriously,” putting limits on how widely a message can be shared to different groups and attaching labels when a message has been forwarded. However, WhatsApp said the issue raised by Check Point was unrelated to its efforts to curb misinformation.Oded Vanunu, head of vulnerability research at Check Point, said the ability to alter messages gave attackers a powerful tool to spread misinformation from what appeared to be a trusted source. It is especially problematic in group chats, which can include up to 256 people. Multiple messages can come in at once and it can be easy to lose track of what someone has said, he said.“The public relies on the integrity of the message,” said Mr. Vanunu. “WhatsApp needs to adjust to prevent this simple manipulation.”For now, the issue appears limited to a discussion among security experts. Both WhatsApp and Check Point Software said they had not seen regular users creating fake quote messages in chats.Check Point said it also discovered a way within group chats to send a message to a specific individual within the discussion. That individual is tricked into believing that the whole group saw the message and responds accordingly.WhatsApp played down the concerns raised by Check Point, saying most people know the person who they are messaging on the service. The company said 90 percent of all messages on the service are sent in one-on-one conversations, and the majority of groups are six people or less — making it less likely that an unknown person can infiltrate a conversation to trick other users.A person can check the validity of a quote message by clicking on it. Doing so will take you back to the point in the chat when the message was sent unless the message was deleted or the person was not a participant in the chat when the message was sent.WhatsApp said the potential fixes to this issue were not worth trying. One solution would be to create transcripts of every message exchange to verify the accuracy of every quote. Creating such a transcript is a significant privacy risk because those accounts of what people wrote to each other must be stored somewhere, the company said.Follow Daisuke Wakabayashi on Twitter: @daiwaka

Supported byBy Remy Tumin and Hiroko Masuike(Want to get this briefing by email? Here’s the sign-up.) Good evening. Here’s the latest.1. Top leaders of intelligence agencies made their annual appearance before the Senate to discuss the biggest threats to national security.Cyberthreats from China and Russia were high on the agenda. Among other observations: North Korea is “unlikely to give up” all of its nuclear stockpiles and Iran is not actively trying to make a nuclear bomb — both direct contradictions of President Trump’s foreign policy tenets. Above from left, the F.B.I. director, Christopher Wray; the C.I.A. director, Gina Haspel; and the director of national intelligence, Dan Coats.Also notable was the absence of any rationale for building a wall along the southwestern border, which Mr. Trump has characterized as the country’s most critical security threat._____2. It’s so cold that…This is not the setup to a bad joke. Temperatures are growing dangerously low across the Midwest this week. You could get frostbite in as little as five minutes; it will be warmer in Antarctica than in Des Moines; it could feel like minus 65 in Minneapolis.Hundreds of schools are being closed, and the governors of Illinois, Michigan and Wisconsin have declared emergencies. Above, Lake Michigan freezing over in Chicago.How can it get so cold if the Earth is warming? Because climate and weather are not the same thing._____3. British lawmakers, voting on a broad spectrum of amendments to Prime Minister Theresa May’s E.U. withdrawal plan, embraced a measure that, in principle, rules out withdrawing without a deal.Parliament also rejected delaying Brexit beyond the March 29 deadline. Above, protesters on both sides of the issue outside Parliament on Tuesday.Before the voting session, Mrs. May raised the stakes by promising to reopen negotiations on the agreement — a 585-page text that the E.U. has said was its final offer. Critics think she is trying to run down the clock to present them with two options: her plan or no deal._____4. The U.S. State Department said it gave Juan Guaidó, above, the right to control Venezuelan assets and property in U.S. banks, one week after he declared himself the interim president of his country.The move is the latest part of the U.S. campaign to oust President Nicolás Maduro, whose re-election has been widely contested — but who still has the backing of the country’s generals.Venezuela has begun moving, carefully, against Mr. Guaidó. The chief prosecutor announced a formal investigation of him for antigovernment activities and encouraging protests. His assets have been frozen, and the government is trying to stop him from leaving the country._____5. Apple appears to be entering a rare period of vulnerability. The company said that profits were flat this quarter compared with a year ago, citing an economic slump in China.Consumer demand in China for expensive iPhones has slowed, particularly with the rise of cheaper, local alternatives. The company is also uniquely vulnerable to tariffs against China, where most of its products are assembled. Above, today at the New York Stock Exchange.And in another embarrassment for Apple, an iPhone bug allowed FaceTime users to eavesdrop through its video and audio calling app. Here’s how to disable FaceTime to avoid the glitch._____6. Pacific Gas and Electric, California’s largest utility, filed for bankruptcy protection. It is facing tens of billions of dollars in liability claims for two years of wildfires.Equipment owned and maintained by the utility sparked at least 17 of the 21 major wildfires that burned through California in 2017, but some argue that climate change and development in remote areas have made blazes more destructive. Above, a PG&amp;E crew working on power lines during the Camp Fire in November.The utility serves 16 million customers, whose electricity might become more expensive as PG&amp;E tries to recoup its losses from the fires. Here are answers to some other big questions about the bankruptcy._____7. Today’s 2020 update: Senator Kamala Harris, the most high-profile and politically connected black woman to run for president, would seem well positioned to secure the support of black voters that buoyed former President Barack Obama in 2008.Yet interviews in early primary states like South Carolina and her home state, California, show the challenges she faces: activists’ skepticism of her record as a prosecutor, the desire for a push further to the left, sexism and some concern that a female candidate might not beat President Trump. Above, Ms. Harris at a local sorority chapter in South Carolina.“I don’t know, I need to see her devotion to the African-American community,” said one resident of Columbia, S.C._____8. Want to know why you fall facefirst into the ocean every time you go surfing? Let’s go to the videotapes.At the new Surf Simply resort in Costa Rica, guests are filmed as they catch a wave, and that’s just the start of personalized, tech-based coaching. Surf Simply is so popular that sessions routinely get booked out a year in advance (a one-week stay starts at about $4,500).One repeat surf guest summed it up: “It’s the school for surf nerds — but it’s the coolest nerds you’ve ever met.”_____9. A few words from the stars.Over four seasons, the Netflix series “Unbreakable Kimmy Schmidt” turned the story of a woman freed after being kidnapped and held underground for 15 years into a sprightly, joyous comedy.As the series ends, its lead actress, Ellie Kemper, above, reflects on what she learned from her castmates and what it’s like to “be a part of a show that seems to make people feel better.”And the actress and director Lena Dunham pays homage to her literary hero, Diana Athill, the British centenarian who died last week after a life of both fierce independence and marvelous affirmation._____10. Finally, Aztec legend meets science.The axolotl, a tube-sock-like salamander, was thought to be a god who transformed himself to avoid sacrifice. Many animals can perform some degree of regeneration, but axolotls can grow back a nearly perfect replica of just about any body part (excepting, of course, the head).Now, researchers reported the most complete assembly of DNA yet for the striking amphibian, also known as the Mexican walking fish. Fully mapping its genome could unlock some of the secrets of regeneration for humans.Have a restorative night._____Your Evening Briefing is posted at 6 p.m. Eastern.And don’t miss Your Morning Briefing. Sign up here to get it by email in the Australian, Asian, European or American morning.Want to catch up on past briefings? You can browse them here.What did you like? What do you want to see here? Let us know at briefing@nytimes.com.

Supported byBreakingviewsBy Richard BealesGet the DealBook newsletter to make sense of major business and policy headlines — and the power-brokers who shape them.__________Tensions over tariffs and pacts like the North American Free Trade Agreement have dominated recent economic headlines, but Thursday’s triple-whammy of cyber hacking news gives justified prominence to what may be an even bigger threat to global prosperity.Cyber crime costs the world almost $600 billion annually, according to a report published earlier this year by the think tank Center for Strategic and International Studies and the cyber security company McAfee. That’s a potential hole of around 0.7 percent in global gross domestic product, as measured by the International Monetary Fund.The I.M.F. said in July that the emergence of a trade war could dent world output by 0.5 percent by 2020. That’s a big concern, but at under $450 billion — calculated by simply translating the total estimated shortfall into dollars — not as large as the annual impact of cyber crime.Investors and companies are aware of both risks. They rank trade-related factors and cyber threats among their top worries, according to surveys by the professional services PricewaterhouseCoopers. But tit-for-tat political rhetoric and tariffs, along with tales of dairy farmers’ personal struggles with trade barriers, often make bigger headlines than stories about the nefarious manipulation of computer software.It is relatively easy, however, to grasp the implications of Bloomberg Businessweek’s investigation into alleged Chinese government interference in the manufacture of cloud-storage hardware used by American giants like Apple and Amazon. It’s also possible to relate to Britain and the Netherlands going after Moscow for trying to hack a multilateral chemical-weapons-monitoring body — especially after the dramatic poisoning of a former double agent in Britain. The same goes for the United States Department of Justice indicting Russian military personnel for cyber intrusions that affected sports-doping watchdogs.In a speech on Thursday, Vice President Mike Pence took aim at Beijing’s various efforts to advance its interests at the expense of Washington’s, from domestic policy to cyber crime and propaganda. Of course, the United States and its allies also participate in cyber offensives aimed the other way.With all this publicity, though, at least investors can’t claim they weren’t warned.Richard Beales is a columnist at Reuters Breakingviews. For more independent commentary and analysis, visit breakingviews.com.Get the DealBook newsletter to make sense of major business and policy headlines — and the power-brokers who shape them.

Supported byAnother ViewBy Craig A. NewmanThe public’s confidence in the capability of companies to protect customers’ personal information has taken a beating in recent weeks.Customers of Sears and Kmart, Best Buy, Saks Fifth Avenue and Lord &amp; Taylor, and Delta Air Lines recently learned that hacks have exposed their personal data, including credit and debit card numbers. And then there’s the disclosure that Cambridge Analytica harvested the personal information of nearly 87 million Facebook users.Despite these disclosures and others, we continue to entrust our personal information to businesses without any standard for judging how safe it is. It doesn’t have to be that way.When we head out for dinner in major cities, for example, the restaurant has a letter grade from the health inspector in the window. As a society, we recognize that when consumers dine out, they may be putting their health at risk. We require, in turn, that restaurants display the simple but powerful information about their hygienic standards.There is no equivalent standard by which a consumer may judge the data security practices of a business.That lack of public information about the cyber-preparedness of businesses is all the more striking given the relative severity of the threat. More than half the adult population of the United States was affected by the breach of Equifax last year.Unfortunately, we have become inured to these hacks. Our response to breaches has become routine: more calls for regulation, followed by congressional hearings and failed regulatory proposals. Consumers go about their lives, numbed by the frequency and the lack of consequences. Meanwhile, the hacks get worse.This cycle stems in part from a lack of information about the security practices of businesses. But forcing companies to explain how they are keeping the bad guys out would only help the bad guys.The simple grading system used by restaurant regulators can and should be a model to inform the public about the digital security of businesses that store sensitive consumer data. A letter grade is a crude measure to assess a complex issue like cybersecurity to be sure, but what the metric lacks in nuance it makes up for with brute force.Current measures to assess cyber-preparedness are either not compulsory or too complex. The federal government’s National Institute of Standards and Technology framework is widely respected, but it’s voluntary, underused and not easily digestible for the average consumer. Only seven Fortune 500 companies mentioned it in their annual filings with the Securities and Exchange Commission last year, and only one said it had adopted it.MSCI — an index provider and independent research firm for institutional investors — ranks companies on cybersecurity. More than a year before Equifax’s breach was revealed, MSCI scored Equifax a 0 out of 10 on privacy and data security. As prescient as it was, consumers would have had difficulty absorbing such a rating, which is just one of several components that MSCI uses to arrive at an environmental, social and governance, or E.S.G., rating of overall corporate citizenship.A new grading system should start with the basics: Are companies on top of data security, and if hacked, do they know how to reduce the impact?Each year, the Ponemon Institute, an independent research group, and IBM look at the cost of the average data security breach, as well as the average cost of each piece of data compromised. In 2017, the average cost of a data breach in the United States was $7.35 million, or $141 per record compromised. But if a company has an incident response team, uses encryption, trains its employees, has a business continuity program and monitors cyber-threat intelligence, that reduces the cost of the average data breach by nearly 47 percent. Using these five factors — weighed for their impact of cost reduction — is a simple starting point.There are plenty of details to be worked out about a cybersecurity grading system. But the one nonnegotiable aspect would be that, once assigned, letter grades must be made highly accessible to the public. Companies should be required to display their grades prominently at their physical locations, on their websites, on certain documents (mortgage applications, for example) and on credit card readers.A grading system would not solve every cybersecurity problem, nor prevent every breach. But our sad state of affairs — in which we are equal parts fearful, apathetic and ignorant about digital security — must change. Providing clearer information to the public is the most productive next step we can take.Craig A. Newman is a partner and chair of the privacy practice at Patterson Belknap Webb &amp; Tyler LLP, the New York law firm.

Supported byBy Nicole Perlroth and David E. SangerThe White House eliminated the position of cybersecurity coordinator on the National Security Council on Tuesday, doing away with a post central to developing policy to defend against increasingly sophisticated digital attacks and the use of offensive cyber weapons.A memorandum circulated by an aide to the new national security adviser, John R. Bolton, said the post was no longer considered necessary because lower-level officials had already made cybersecurity issues a “core function” of the president’s national security team.Cybersecurity experts and members of Congress said they were mystified by the move, though some suggested Mr. Bolton did not want any competitive power centers emerging inside the national security apparatus.The decision was criticized by Mark R. Warner, a senator from Virginia and the ranking Democrat on the Senate Intelligence Committee. “I don’t see how getting rid of the top cyber official in the White House does anything to make our country safer from cyber threats,” he wrote on Twitter.It was the latest in a series of steps that appeared to run counter to the prevailing view in Washington of cybersecurity’s importance.Two years ago, a commission established by President Barack Obama urged elevating the cybersecurity coordinator job and turning the position into an assistant to the president, on par to the assistant to the president for counterterrorism and homeland security — a reflection that various federal agencies did not have clear lines of authority or clear strategies in cybersecurity.President Trump began his administration with two respected veterans of cyber policy. He appointed Thomas P. Bossert, a lawyer in the administration of President George W. Bush, as the homeland security adviser.The cybersecurity coordinator who reported to him, Rob Joyce, had run the Tailored Access Operations unit of the N.S.A. — the unit that, until it was reorganized and renamed, was responsible for breaking into foreign computer systems as part of United States covert operations.Mr. Bossert and Mr. Joyce said Russia and North Korea were the culprits in major cyberattacks over the last year, and together they developed a system for making more public the decisions about which vulnerabilities to turn over to the private sector for patching — and which to retain in America’s arsenal for possible offensive use.Mr. Bossert was forced out on Mr. Bolton’s second day on the job, and Mr. Joyce returned to the N.S.A. on Friday.It is unclear how those issues will now be managed in the White House. Mr. Bolton has virtually no cyber-related experience. When he was last in government, as ambassador to the United Nations under President George W. Bush, cybersecurity was not formally considered a national threat. It is now listed as the No. 1 threat in the annual assessment that the director of national intelligence sends to Congress.Mr. Bolton has talked about “streamlining” the N.S.C., and so far that appears to have involved reducing many of the new positions created over the past decade.Mr. Bolton’s decision was first reported by Politico.The elimination of the cybersecurity role is likely to increase concern that the Trump administration is short-handed and unprepared to deal with increasing cybersecurity threats. The White House still has not presented a coherent plan to protect election systems in advance of the fall midterm elections.Russian hackers are believed to have penetrated election computers in a number of states, though there is no evidence that vote counts were changed. And authorities say hackers with Kremlin ties engaged in a wide-ranging campaign to attack the computer systems of Democratic officials and spread misinformation on social media before and after the 2016 presidential election.Security experts are also worried that hackers operating out of Iran or Russia could renew their efforts to penetrate computer systems in the United States, including machines that operate critical infrastructure like the electric power grid.The responsibilities of White House cybersecurity coordinator will be delegated to two members of the N.S.C.’s team.Joshua Steinman, who had little cybersecurity policy experience before joining the N.S.C., will assume responsibility for offensive policy, including responses to cyberthreats from foreign adversaries. The defensive and homeland security responsibilities will fall to Grant Schneider, who already serves in a dual role as acting United States chief information security officer and senior director for cybersecurity at the N.S.C.“Moving forward, these senior directors will coordinate cyber matters and policy. As they sit six feet apart from one another, they will be able to coordinate in real time,” Robert Palladino, an N.S.C. spokesman, said in a statement.Cybersecurity policy experts had been pressing the administration in recent weeks to keep the position. Michael Daniel, who was White House cybersecurity coordinator under the Obama administration, said the Trump administration was sending a message that “cybersecurity is not very important.”“The position is actually a very important one,” Mr. Daniel said. “The cyber threat landscape only getting worse, it’s not getting easier right now.”Follow Nicole Perlroth and David E. Sanger on Twitter: @nicoleperlroth and @SangerNYT

Supported byWhite Collar WatchBy Peter J. HenningAgatha Christie’s fictional sleuth Miss Marple once said in a BBC adaptation that “good advice is almost certain to be ignored, but that’s no reason for not giving it.” That may reflect how companies will respond to guidance recently issued by the Securities and Exchange Commission about how companies should deal with cybersecurity threats.Security breaches at companies like Equifax, Target and Yahoo over the past few years have exposed the personal information of millions of consumers. The federal government isn’t immune to hackers, either. The systems of the Office of Personnel Management and even the S.E.C. have been breached.The response from companies usually seems to be about keeping a lid on the hack. That’s something the S.E.C. would like to end, but its guidance may not go very far in changing how companies deal with cybersecurity issues.The S.E.C.’s guidance is full of good advice. The regulator tells companies that they need to have in place “disclosure controls and procedures that provide an appropriate method of discerning the impact that such matters may have on the company and its business, financial condition and results of operations.” Just as important, companies are expected “to disclose cybersecurity risks and incidents that are material to investors, including the concomitant financial, legal or reputational consequences.”Those are worthwhile reminders, but the S.E.C. has yet to institute any direct measures to compel companies to reveal the nature and scope of a cybersecurity breach.The Equifax breach, which affected more than 140 million people, came to the company’s attention in late July, but the public didn’t learn of it until early September. Whether keeping quiet for almost six weeks can be considered timely disclosure is an open question, but nothing happened to the company because of the delay.There will always be at least some lag time between discovering a theft of information and an assessment of its extent. Hackers don’t want to be discovered, so the scope of a breach may not be immediately apparent. But the S.E.C. pointed out that “an ongoing internal or external investigation — which often can be lengthy — would not on its own provide a basis for avoiding disclosures of a material cybersecurity incident.”The S.E.C. also warns companies about the potential for insider trading when they learn about a breach, which inevitably has a negative effect on the stock price once it is disclosed. It cautioned that “companies would be well served by considering how to avoid the appearance of improper trading during the period following an incident and prior to the dissemination of disclosure.”For example, just a few days after the breach at Equifax came to the company’s attention, four members of management, including the chief financial officer, sold $1.8 million worth of shares. An investigation by a special committee of the board of directors exonerated them, finding that none knew about the breach at the time, a key requirement to prove insider trading.The problem is that even the perception that corporate executives sold shares ahead of disclosing a cybersecurity problem can compound the negative publicity surrounding a breach.The S.E.C.’s guidance is certainly welcome, and it may nudge companies to be more aggressive in policing stock sales when a cybersecurity problem comes to light. The problem is that the advice can be easily ignored when a breach occurs. If the S.E.C. wants to send a message to companies, it may need to ratchet up the pressure by pursuing an enforcement action.Nothing gets the attention of corporate directors and executives like a case that describes how a failure to respond in a timely fashion resulted in a violation of disclosure requirements.The problem is that proving a case can be difficult because the standard for when information must be revealed is so elastic. Companies must reveal “material” information in a timely manner, which the Supreme Court said in Basic v. Levinson depended “on the significance the reasonable investor would place on” it. The point at which a cybersecurity breach reaches that level is almost impossible to describe with any precision.And that gives companies flexibility in deciding when the handiwork of hackers becomes material information for investors, despite the S.E.C.’s push for earlier disclosure.

Supported byBy Adam BaidawiMELBOURNE, Australia — The Australian government presented its annual cybersecurity report on Tuesday, revealing that one of its national security contractors had suffered a breach in which it lost a “significant amount of data” last year.Included in the report was a case study that said the government’s cybersecurity team discovered that an attacker had compromised the network of a “small Australian company with contracting links to national security projects,” adding that the attacker was on the network for an “extended period of time.”Though the report outlined the breach as a case study, Dan Tehan, a minister tasked with advising the prime minister on cybersecurity, did not divulge specifics to the local news media about who was affected or what data might have been compromised. “We don’t know and we cannot confirm exactly who the actor was,” he said Tuesday on ABC Radio.The revelation of the security contractor’s breach, and the lack of detail surrounding it, comes at a time of increased concern over the government’s ability to protect citizens’ personal information — especially when accounting for third parties that have access to sensitive data.Last week, Prime Minister Malcolm Turnbull introduced a far-reaching plan to collect Australians’ driver’s license photos and distribute them across security agencies, leaving open the possibility of sharing them with private companies. Privacy advocates criticized the plan as risky, with some pointing to a hacking attack on Australian census data last year, and the revelation this year that Australians’ Medicare card details were being sold on the web for less than 30 Australian dollars, or around $23.Experts say that private industry has been one of the most glaring vulnerabilities in Australia’s cybersecurity. Tuesday’s report, the Australian Cyber Security Center Threat Report, noted that 734 private-sector systems of “national interest” were affected by cyberattacks last year.“Certain companies take cybersecurity quite seriously,” said Alana Maurushat, academic co-director of the Cyberspace Law and Policy Center at the University of New South Wales in Sydney. “But you have key industries to Australia who — while there may not be the same media coverage — you know through internal sources are being breached. Our mining industry has notoriously been rumored to have been breached by competitors.”Ms. Maurushat said that Australia as a whole was not far behind the rest of the developed world’s level of cybersecurity, but emphasized concerns about its private sector.“The crazy thing about this is that they don’t even know that they’ve been breached,” she said. “There are certain breaches that occur, and there are studies on this, where sometimes someone would be on your system for almost a year, without the breach even being noticed. That’s the stuff that keeps me up at night.”A cybersecurity report released this year by Telstra, the country’s dominant telecommunications company, said that 59 percent of surveyed companies in Australia had detected a security breach on at least a monthly basis. A similar number reported experiencing at least one ransomware attack. Over half of Australian organizations that came under such an attack paid the ransom, the report said.Ms. Maurushat said that, in part, Australia’s private-sector cybersecurity was lacking because of an acute shortage of skilled workers.The government report also noted “extensive” state-sponsored activity against Australia’s government, saying that its defense contractors continued to be targeted by foreign nations’ cyberespionage efforts.At a news conference on Tuesday, Mr. Tehan said that the government was pivoting toward offensive capabilities to “prevent and shut down safe havens for offshore cybercriminals.”Last year, the Australian government blamed foreign actors for an attack on its online census portal.“The whole census thing — that’s an I.B.M. mistake,” Ms. Maurushat said, referring to the technology company’s contracting role in the census. “That’s not a government mistake, that’s an industry mistake, from a company you wouldn’t expect to make those errors.”In a settlement over the census problems, I.B.M. paid the government about 30 million Australian dollars, or about $23 million.Not unlike vaccines and herd immunity, Ms. Maurushat said, a government’s cybersecurity is only as strong as those it chooses to share its data with.When asked whether Australia’s lagging digital infrastructure and poor internet speeds might have a detrimental effect on its security, Ms. Maurushat said that a beleaguered attempt to speed up Australia’s internet, the National Broadband Network initiative, may prove to be a silver lining.“It’s the opposite,” she said, adding that hackers rely on fast internet speeds. “So in some ways, if the N.B.N. is a disaster, it might be better for us.”Follow Adam Baidawi on Twitter @ads_b

Supported byBy David D. KirkpatrickLONDON — Russian hackers over the past 12 months have tried to attack the British energy, telecommunications and media industries, the government’s top cybersecurity official said Tuesday in a summary of a speech to be delivered on Wednesday.The warning, by Ciaran Martin, chief of the National Cyber Security Center, is the strongest indication yet that Russian cyberattacks on Western governments and industries may be far more persistent than United States or British officials have previously acknowledged.The speech also appeared to fit into a coordinated effort by the British government to publicly warn Russia that its efforts have been noticed. In a speech on Monday night, Prime Minister Theresa May addressed Russia directly. “We know what you are doing,” Mrs. May said. “And you will not succeed.” She accused the Kremlin of “threatening the international order on which we all depend.”Taken together, the two speeches are a sharp escalation in the public accusations around a conflict that has so far remained mostly in the shadows. Recent high-profile cyberattacks, however, have put new pressure on politicians to defend against the dangers.The most spectacular example is the break into the computer systems of the American Democratic Party during the 2016 presidential campaign, an attack American intelligence agencies have attributed to Russian hackers.But Britain this year was hit by the so-called WannaCry cyberattack, carried out by North Korea. It temporarily disabled the computer systems at several British hospitals, forcing the diversion of ambulances and the rescheduling of operations, before it was stopped by the lucky break of a lone amateur who successfully defused it.American government officials also reportedly concluded over the summer that Russia had penetrated the computer networks of companies that operate nuclear power stations and other energy facilities, evidently gathering information and probing for vulnerabilities. No operations were disrupted.The Russians also reportedly tried to break into the Irish electrical grid last summer, and British officials warned at the time that they appeared to be singling out British power companies as well. Russian hackers have successfully shut down power for a time in parts of Ukraine, which the Russians appear to treat as laboratory for testing such tactics.British and American intelligence officials say the Kremlin has deliberately cultivated a cottage industry of criminal hackers loosely affiliated with Russian intelligence agencies. Russian intelligence officials sometimes personally profit from the revenue from cybercrimes, and at other times they direct the hackers toward sabotage, espionage or other less lucrative objectives.Among other victories, the Russians appear to have collaborated with a group calling itself Shadow Brokers to release a trove of cyberespionage tactics stolen from the computers of the National Security Agency, including some incorporated in the WannaCry virus that have now been used against Western industries and governments.The summary released Tuesday of Mr. Martin’s speech provided no details of the specific Russian attacks over the last year on British energy, telecommunications or media companies. Nor did the statement discuss any possible Russian efforts to use social media or cyberespionage to influence elections in Britain, as the Kremlin has recently sought to do in the United States and France.But Mr. Martin said that fears of Russian election meddling have grown increasingly widespread throughout Europe. At a conference organized last month by the National Cyber Security Center, he said, two-thirds of the member states of the European Union were concerned about potential Russian interference in their internal elections.

Supported byBy Tariq PanjaEngland’s soccer federation has written to FIFA to express concerns about the leak of confidential antidoping correspondence by a hacking group believed to be based in Russia, and to request assurances about the soccer governing body’s cybersecurity preparations ahead of next year’s World Cup there.Since last year, leaks by the hacking group, known as Fancy Bears, have revealed confidential medical information of scores of top athletes, including tennis champions, track stars and an Olympic gymnast, who had received exemptions to take medication usually be banned under doping regulations. In August, the group turned its attention to soccer, naming 25 players granted similar waivers, known as therapeutic use exemptions, to take otherwise prohibited substances at the 2010 World Cup.Even before that hack, though, which also included an email from England’s Football Association’s integrity chief to FIFA, the English had been bolstering their cybersecurity to counter the growing threat from hackers worldwide, according to two people familiar with the organization’s plans. Among the precautions expected to be in place in Russia next year — England can qualify with a win or draw in its next match — England’s players and staff will be told to avoid public Wi-Fi networks as well as those in their team hotels, according to people familiar with the F.A.’s plans.The Football Association declined to comment on the letter, though FIFA confirmed its existence.“We can confirm that The F.A. has sent a letter to FIFA related to the Fancy Bears attack,” a FIFA spokesman said. “In its reply, FIFA has informed The F.A. in such context that FIFA remains committed to preventing security attacks in general, and that with respect to the Fancy Bears attack in particular it is presently investigating the incident to ascertain whether FIFA’s infrastructure was compromised.”In mocking messages revealing the 25 players’ names last month, the hackers also claimed there had been hundreds of positive doping tests in soccer in 2015 and 2016, including four in Britain linked to the use of the recreational drugs cocaine and ecstasy.WADA said its servers had not been compromised in the soccer case, suggesting the information had been acquired from FIFA’s computer systems.Coaches at the World Cup zealously guard their tactics and team selection plans for the monthlong event, often erecting fences around training fields to prevent such information from leaking out. Shortly before France’s opening game at the 2014 World Cup in Brazil, a drone hovered above the team’s practice session, leading the team’s coach to express concerns about possible spying. At the 2015 Rugby World Cup, photographers managed to capture details of Australia’s tactics after staff members failed to keep them covered during preparations for the championship match against New Zealand.Fancy Bears’ original leaks about international athletes emerged about four months after the The New York Times published the account of Russia’s longtime antidoping chief, who revealed that he had run a yearslong doping program involving top Russian athletes. The hacks also are seen as a response to sports federations who banned Russian athletes from the 2016 Rio Olympics.Russia has denied that its government is behind the attacks. But law enforcement authorities have determined they originated there, according to the World Anti-Doping Agency.“For the purposes of computer security in general, FIFA is itself relying on expert advice from third parties,” FIFA’s spokesman said. “It is for this reason that FIFA cannot and does not provide any computer security advice to third parties.”

Supported byBitsBy Sheera FrenkelEach week, technology reporters and columnists from The New York Times review the week’s news, offering analysis and maybe a joke or two about the most important developments in the tech industry. Hi everyone! I’m Sheera Frenkel, your friendly cybersecurity correspondent. To do my job, I have to spend a lot of time on Facebook and Twitter. And the more time I spend studying those sites, the less I find myself actually using them.Which brings me to the tech news for this past week — in which everyone seemed to be obsessed with who was, or wasn’t, allowed on Twitter.We started the week with a lingering question: Why was Twitter allowing Alex Jones, notorious far-right conspiracy theorist, to tweet?Mr. Jones and accounts associated with his media website Infowars were booted from Apple, Facebook, YouTube and other platforms last week for violating policies against hate speech. But Twitter did not ban Mr. Jones and Infowars, saying they had not violated its policies. Yet Twitter struggled to define its policies to my colleagues Cecilia Kang and Kate Conger when they visited the company last week.After journalists turned up examples of Mr. Jones’s tweets that contravened Twitter’s rules, the company said on Tuesday that it would suspend him from the platform for seven days after he tweeted a video calling for his supporters to get their “battle rifles” ready against the media and others. But the move was a temporary fix, and we still don’t know what exactly Twitter will and won’t allow on its service.That brings us to our next big Twitter question: Was Tesla chief executive Elon Musk on drugs when he tweeted on Aug. 7 that he was taking his company private?I’m asking thanks to rapper Azealia Banks, who took to Instagram this past week to recount how she had spent the weekend at Mr. Musk’s house waiting to record an album with his girlfriend, the electronic musician Grimes. Grimes, Ms. Banks said, never showed up. Then Ms. Banks dropped this bombshell: “Lol I waited around all weekend while Grimes coddled her boyfriend for being too stupid to know not to go on Twitter while on acid.”That immediately caught the attention of Tesla fans who were struggling to make sense of what was going on after Mr. Musk had announced on Twitter that he had secured funding to take the electric car maker off the public market at about $420 per share. The casual way in which Mr. Musk just tweeted the news out without regard to process raised a kerfuffle. And last week, the Securities and Exchange Commission served Tesla with a subpoena to learn more about the circumstances of the tweet.On Thursday, in an interview with The New York Times, Mr. Musk was asked if drugs were involved in his market-moving tweet. “Absolutely not,” he said.Andrew Ross Sorkin, our Dealbook columnist, wondered whether Twitter is the right forum for public company executives to be talking in the first place. And Kara Swisher, a contributing opinion columnist for The Times, asked on Thursday whether Mr. Musk was just plain crazy. She concluded that he wasn’t, but recommended that he delete the Twitter app from his phone.It isn’t bad advice. And neither is the advice our editors regularly give us when we are tempted to weigh in on a Twitter brawl: When in doubt, never tweet.In other tech news this past week:■ Google employees signed an internal letter protesting the company’s decision to build a censored version of its search engine for China. The letter, first reported by my colleagues Kate Conger and Daisuke Wakabayashi, was the latest example of how Google employees have challenged the company’s leadership. It also complicates Google’s attempt to return to China, which it withdrew from eight years ago to object to Beijing’s restrictions on free speech and hacking.■ File this under how the rich just keep getting richer. My colleague Erin Griffith wrote this week about how Silicon Valley start-ups are being showered with so much money — funding rounds of $100 million and up known as mega-rounds are booming — that they are struggling to figure out what to do with all of it.■ Cuba is one of the few remaining parts of the world where people still struggle to get online. But for nine hours on Tuesday, Cubans suddenly had the internet. During the duration of a test being run by the Cuban government, which partnered with a wireless internet company, Cubans could get online for free using their cellphones.■ The fake internet keeps getting more real. I wrote a story about a fake Facebook group that tricked Americans into showing up at protests. The group, Black Elevation, was one of dozens removed by Facebook for being part of an influence campaign trying to sway Americans ahead of the midterm elections.■ And lastly, this long read by Reuters was an incredible documentation of the ways in which Facebook’s failings in Myanmar led to people being killed. A lot has been written about how Facebook was used to spread hate speech in Myanmar, which led to brutal attacks against the country’s Rohingya minority. Reuters revealed that Facebook initially had only two Burmese speakers reviewing content from Myanmar and that it later turned to contractors. After Reuters’s report, Facebook announced it was hiring policy advisers on Myanmar and more Burmese-language moderators.Sheera Frenkel covers cybersecurity for The Times. She previously worked at Buzzfeed and spent years as a correspondent in the Middle East. Follow her on Twitter: @sheeraf.

Supported byBy Sui-Lee WeeBEIJING — As China moves to start enforcing a new cybersecurity law, foreign companies face a major problem: They know very little about it.The law — which was rubber-stamped by the country’s Parliament last year — is part of wide-ranging efforts by Beijing to manage the internet within China’s borders. Those efforts have been stepped up in the years since Edward J. Snowden, the whistle-blower and former American intelligence contractor, revealed that foreign technology firms could help governments spy.And while Chinese officials say the new rules will help guard against cyberattacks and prevent terrorism, critics, many of them from businesses, have their concerns. Companies worry that parts of the new law, which takes effect on Thursday, will make their operations in China less secure or more expensive. In some cases, they argue, it could keep them out entirely.The law will have a big impact on how business is done in China, said Michael Chang, an executive with the Finnish technology company Nokia and the vice president of the European Union Chamber of Commerce in China. But, he said, “There’s unfortunately a lot of confusion.”“Industry is not ready because the implementation rules are not clear,” Mr. Chang said, speaking at an event organized by the lobbying group to announce the results of its annual business confidence survey.“We still have a lot of unclarified territory that needs to be addressed as soon as possible.”The law would require that companies store their data within China, and would impose security checks on companies in sectors like finance and communications. Individual users, meanwhile, would have to register with their real names to use messaging services.But Mr. Chang said that officials had conveyed “less than half” of the specifics of how the law would be implemented.“A wide range of companies are doing data transfers — it’s the lifeblood of their business,” he said.Executives have complained that the wording of the law is ambiguous, fearing that it gives China’s ruling Communist Party substantial leeway to target them.One instance cited by Mats Harborn, president of the European Union Chamber of Commerce in China, in a round-table discussion with journalists, was that the government said it wanted to regulate “critical information infrastructure,” but had not defined what that meant.“The way it’s enforced and implemented today and the way it might be enforced and implemented in a year is a big question mark,” added Lance Noble, the chamber’s policy and communications manager. He warned that uncertainty surrounding the law could make foreign technology firms reluctant to bring their best innovations to China.In May, a coalition of business lobby groups representing European, American and Asian companies called on China to delay implementing the law, while the European Union Chamber of Commerce in China asked for additional time to allow companies to adhere because of the “substantial compliance obligations.”The Cyberspace Administration of China, the country’s internet regulator, has so far decided to delay implementation only of the regulations governing cross-border data flow, which will now take effect at the end of 2018, according to a revised draft of the rules that was seen by The New York Times.The regulator could not be reached despite multiple telephone calls.Paul Triolo of the political risk consultancy Eurasia Group noted the decision to delay that component of the law, saying in a report last week that “getting the cross-border data flow issue right is a prerequisite for Beijing’s efforts to promote economic globalization.” He wrote that China, for the time being, “is eager to avoid being seen as stifling digital trade.”The European Union and China plan to hold a summit meeting on Thursday in Brussels. Friction between them has mounted after the European Union imposed anti-dumping duties on Beijing, accusing it of flooding the European market with cheap steel.Many foreign companies are becoming increasingly skeptical of China’s promises of economic reform. Mr. Harborn, the lobbying group president, said he expected European officials to complain to Premier Li Keqiang of China about unequal market access in the country for European companies.The European Union Chamber of Commerce in China said that half the members who took part in its annual business confidence survey reported higher sales in China last year, thanks largely to a Chinese government stimulus package in the first half of the year. But 40 percent of respondents said they believed regulatory barriers would increase over the next five years.Follow Sui-Lee Wee on Twitter @suilee.Paul Mozur contributed reporting from Hong Kong. Carolyn Zhang contributed research from Shanghai.

Supported byletterA cybersecurity expert says multifactor authentication has had a positive effect.To the Editor:Re “Perils of Two-Step Authentication” (Op-Ed, Jan. 28):Josephine Wolff raises legitimate questions about the effectiveness of two-factor authentication and its use as a best practice. But she engages in the timeless tradition of using FUD — fear, uncertainty and doubt — to make her argument. Certainly, multifactor authentication is not the holy grail in identity authentication, but it has had a positive effect in securing data compared with the password-only approach, which has failed miserably. Until we are able to move security completely away from the end user, the end user has a responsibility to do whatever he or she can to manage risk. There will always be vulnerabilities in cybersecurity. Our objective should be to create resilient solutions that manage risk effectively. Best practices are used because they are informed approaches and solutions to common challenges. As we seek to create a culture of cybersecurity awareness around the globe, the best practice of multifactor authentication is not the ultimate goal, but is certainly an important step forward in educating the user on his or her responsibility in cyberspace. Kiersten E. TodtArlington, Va.The writer, a former executive director of the Presidential Commission on Enhancing National Cybersecurity, is managing director of the Cyber Readiness Institute, a nonprofit.

Supported byBy Jamie TarabaySYDNEY, Australia — Prime Minister Scott Morrison of Australia on Monday blamed a “sophisticated state actor” for the recent hacking of Parliament’s computer network, raising the specter of foreign interference in the country’s politics weeks before a national election.The government has not identified the country behind the attack, but Mr. Morrison said that along with Parliament, the networks of the major political parties were also affected.Mr. Morrison did not detail how the country’s security agencies had detected or dealt with the malicious activity, but he insisted that “there is no evidence of any electoral interference.”Cybersecurity experts, he said, briefed the country’s electoral commissions and met with state and territory officials. “They have also worked with global antivirus companies to ensure Australia’s friends and allies have the capacity to detect this malicious activity,” he said.Alastair MacGibbon, the national cybersecurity adviser, said on Monday that the government had not learned the identity of the hacker before it acted to block the activity.That defensive action, he said, “also does other unpleasant things, like remove some of the forensic evidence we’re interested in.”A government cybersecurity expert said one difficulty in identifying the perpetrators was that the hackers used tools that had not previously been seen.The nations most likely to carry out such an attack are China and Russia, security experts said, though Iran, Israel and North Korea also have sophisticated cyberwarfare capabilities.Australia has frequently warned of Chinese interference in its politics. Last year, the government barred the Chinese technology giant Huawei from building a 5G telecommunications network. In a speech in October, the head of the Australian Signals Directorate, an intelligence agency, hinted that the decision was about maintaining the integrity of data and critical infrastructure.“If it is China, then I think it’s important for the public to know that,” said Alex Joske, a researcher at the International Cyber Policy Center in Canberra. “Discussions about Huawei and influence will be issues during the election, and letting the public know that the Chinese Communist Party was in our system is important knowledge.”Mr. Joske said Russia, which interfered in the 2016 United States presidential election, had less interest in the Australian election.After the American experience in 2016, Western democracies should be increasingly aware of the vulnerability of their institutions, said Roderick Jones, founder and president of the cybersecurity firm Rubica in San Francisco.“It is gross negligence to have any significant breach of a system at this point, given everything that’s happened around the world, to have a penetration of a parliamentary system is just negligent,” he said.The Australian hack was above all designed to damage voter confidence, Mr. Jones said.“People are suddenly questioning electronic voting, some of those processes get brought into focus and people stop having trust in them. Every Western election has had interference, every one has been damaged in some way. Russia and China are more allied than ever to destroy confidence in the system,” he said.The prime minister’s acknowledgment of the hack represented a departure from past policy, in which the government has been reluctant to single-handedly call out cyberattacks by foreign governments. Last April, Australia, the United States and Britain accused Russia of state-sponsored hacking. In December, Australia followed the United States in condemning Chinese hackers for trying to steal intellectual property.The Australian government’s conundrum now is what it will do once it has uncovered the identity of the foreign state actor, said Fergus Hanson, head of the International Cyber Policy Center.“This sets up Australia for its first attribution without a coalition, it’s never had the confidence to say that for an attack that just affected Australia,” he said. “In a couple of months’ time, they’re going to have to come out and say who was behind it and then they’ll have to react to it.”How the Australian government responds will be closely watched, not least by the other members of the Five Eyes intelligence-sharing alliance: the United States, Britain, Canada and New Zealand.“Will Australia fall out of the intelligence-sharing community if it doesn’t act, or is shown to have less than robust cybersecurity around key infrastructure?” asked Mr. Jones of Rubica. “There’s not a lot Australia can do, but that’s the point of alliances.”Because of an editing error, an earlier version of this article misstated the nationality of Roderick Jones, founder and president of the cybersecurity firm Rubica. He is British, not American.Want more Australia coverage and discussion? Sign up for the weekly Australia Letter, start your day with your local Morning Briefing and join us in our Facebook group.

Supported by“Even the smallest country, on a very low budget, can have an offensive capability.”ROBERT JOHNSTON, founder of the cybersecurity firm Adlumin and a key investigator on Russia’s 2016 hacking of the Democratic National Committee, on the proliferation of privatized spies for digital warfare.

FeatureAs the midterms approach, America’s electronic voting systems are more vulnerable than ever. Why isn’t anyone trying to fix them?CreditCreditPhoto illustration by Javier Jaén. Source photograph: Getty ImagesSupported byBy Kim ZetterIt was mid-July 2016 when Neil Jenkins learned that someone had hacked the Illinois Board of Elections. Jenkins was a director in the Office of Cybersecurity and Communications at the Department of Homeland Security, the domestic agency with a congressional mandate to protect “critical infrastructure.” Although election systems were not yet formally designated as such — that wouldn’t happen until January 2017 — it was increasingly clear that the presidential election was becoming a national-security issue. Just a month before, Americans had been confronted with the blockbuster revelation that Russian government actors had hacked the Democratic National Committee’s servers and stolen private email and opposition research against Donald Trump, the Republican presidential candidate.And now, it emerged, someone was trying to infiltrate the election system itself. The Illinois intruders had quietly breached the network in June and spent weeks conducting reconnaissance. After alighting on the state’s voter-registration database, they downloaded information on hundreds of thousands of voters. Then something went wrong, and the attackers crashed a server, alerting officials to their presence.It soon became clear that this would not be the last attack. In early August, Jenkins learned of another breach, this one on an Arizona state website, and it appeared to come from one of the same I.P. addresses that had been used to attack Illinois. This time, the intruders installed malware, as if setting the stage for further assault. Then reports from other states began to pour in, saying that the same I.P. addresses appeared to be probing their voter-registration networks. Against that backdrop, the D.N.C. hack was looking less like an isolated incident.“We started to ask: Are these things related?” Jenkins recalled. “Are they the same actors? Is this some kind of concerted effort?” He and his team realized that if Russian hackers were trying to disrupt the coming elections, D.H.S. needed to quickly get in touch with the state and local officials who ran them. But whom do you call when there are more than 10,000 election jurisdictions in the United States?Jenkins at first assumed that each state had a chief information officer who oversaw election security — but this turned out to be wrong. A staff member suggested that the Federal Election Commission must be the governing body over elections — but the F.E.C., they quickly realized, was focused on campaign finance, not election systems. Then a colleague did a Google search on election administration and came across the U.S. Election Assistance Commission, the federal body created by Congress in 2002 to serve as a federal liaison with state election officials. “I’m embarrassed to admit I didn’t know that the E.A.C. existed,” Jenkins said. “I would say that I’m not the only person working in the federal government that this was true for. This topic is not something that was really on anybody’s big radar.”Jenkins planned a call for mid-August for his boss, Secretary of Homeland Security Jeh Johnson, to discuss the problem with members of the E.A.C. and the National Association of Secretaries of State. But Jenkins’s knowledge of election hacking was limited to a conference panel he was on six months earlier about the security of internet voting. Although most American voters cast ballots in person or by mail, 31 states and the District of Columbia offer some form of internet voting to military personnel and citizens living overseas. Jenkins, concerned that Russian hackers might interfere with those ballots, intended to offer election officials a simple plan: “We were going to tell them that internet voting wasn’t safe, and it was a risk factor and you need to not do it.”But when Jenkins met E.A.C. officials and the executive director of the National Association of Secretaries of State for a brief discussion before the scheduled call, what was supposed to be a half-hour meeting bled into four hours, as he and his staff got a crash course in election administration. Internet voting, they learned, was the least of their concerns; the real problems were the machines used to cast and tally votes and the voter-registration databases the Russians had already shown interest in hacking. The entire system — a Rube Goldberg mix of poorly designed machinery, from websites and databases that registered and tracked voters, to electronic poll books that verified their eligibility, to the various black-box systems that recorded, tallied and reported results — was vulnerable.In August 2016, though, there was no time to address systemic problems. Many states would begin early voting in five to six weeks, and the machines themselves had to be programmed and locked down well in advance of Election Day. The Department of Homeland Security had to settle for doing Band-Aid security before the election, and even then only with states that requested help — mostly this involved remote-scanning internet-facing servers for known software vulnerabilities that could be patched, and providing a list of security best practices, like making sure vote-tabulation machines were not connected to the internet. Jenkins said the problems the agency couldn’t address were “troubling” but beyond its control. “You could spend years working on connectivity between voting machines and ballot-creating devices and try to get those things fixed,” he said. “But when you’re trying to do something quickly with a group of people who are resource-constrained as severely as election officials are, you kind of have to focus where you can focus.”Two years later, as the 2018 elections approach, the American intelligence community is issuing increasingly dire warnings about potential interference from Russia and other countries, but the voting infrastructure remains largely unchanged. D.H.S. has now conducted remote-scanning and on-site assessments of state and county election systems, but these are still largely Band-Aid measures applied to internet-facing servers. They don’t address core vulnerabilities in voting machines or the systems used to program them. And they ignore the fact that many voting machines that elections officials insist are disconnected from the internet — and therefore beyond the reach of hackers — are in fact accessible by way of the modems they use to transmit vote totals on election night. Add to this the fact that states don’t conduct robust postelection audits — a manual comparison of paper ballots to digital tallies is the best method we have to detect when something has gone wrong in an election — and there’s a good chance we simply won’t know if someone has altered the digital votes in the next election.How did our election system get so vulnerable, and why haven’t officials tried harder to fix it? The answer, ultimately, comes down to politics and money: The voting machines are made by well-connected private companies that wield immense control over their proprietary software, often fighting vigorously in court to prevent anyone from examining it when things go awry. In Ohio in 2004, for example, where John Kerry lost the presidential race following numerous election irregularities, Kerry’s team was denied access to the voting-machine software. “We were told by the court that you were not able to get that algorithm to check it, because it was proprietary information,” Kerry recalled in a recent interview on WNYC’s “Brian Lehrer Show.” He was understandably rueful, arguing how wrong it was that elections are held under “the purview of privately owned machines, where the public doesn’t have the right to know whether the algorithm has been checked or whether they’re hackable or not. And we now know they are hackable.”The ballot box is the foundation of any democracy. It’s not too grand to say that if there’s a failure in the ballot box, then democracy fails. If the people don’t have confidence in the outcome of an election, then it becomes difficult for them to accept the policies and actions that pour forth from it. And in the United States, it’s safe to say, though few may utter it publicly, that the ballot box has failed many times and is poised to fail again.There are roughly 350,000 voting machines in use in the country today, all of which fall into one of two categories: optical-scan machines or direct-recording electronic machines. Each of them suffers from significant security problems.With optical-scan machines, voters fill out paper ballots and feed them into a scanner, which stores a digital image of the ballot and records the votes on a removable memory card. The paper ballot, in theory, provides an audit trail that can be used to verify digital tallies. But not all states perform audits, and many that do simply run the paper ballots through a scanner a second time. Fewer than half the states do manual audits, and they typically examine ballots from randomly chosen precincts in a county, instead of a percentage of ballots from all precincts. If the randomly chosen precincts aren’t ones where hacking occurred or where machines failed to accurately record votes, an audit won’t reveal anything — nor will it always catch problems with early-voting, overseas or absentee ballots, all of which are often scanned in county election offices, not in precincts.Direct-recording electronic machines, or D.R.E.s, present even more auditing problems. Voters use touch screens or other input devices to make selections on digital-only ballots, and votes are stored electronically. Many D.R.E.s have printers that produce what’s known as a voter-verifiable paper audit trail — a scroll of paper, behind a window, that voters can review before casting their ballots. But the paper trail doesn’t provide the same integrity as full-size ballots and optical-scan machines, because a hacker could conceivably rig the machine to print a voter’s selections correctly on the paper while recording something else on the memory card. About 80 percent of voters today cast ballots either on D.R.E.s that produce a paper trail or on scanned paper ballots. But five states still use paperless D.R.E.s exclusively, and an additional 10 states use paperless D.R.E.s in some jurisdictions.The voting-machine industry — an estimated $300-million-a-year business — has long been as troubling as the machines it makes, known for its secrecy, close political ties (overwhelmingly to the Republican Party) and a revolving door between vendors and election offices. More than a dozen companies currently sell voting equipment, but a majority of machines used today come from just four — Diebold Election Systems, Election Systems &amp; Software (ES&amp;S), Hart InterCivic and Sequoia Voting Systems. Diebold (later renamed Premier) and Sequoia are now out of business. Diebold’s machines and customer contracts were sold to ES&amp;S and a Canadian company called Dominion, and Dominion also acquired Sequoia. This means that more than 80 percent of the machines in use today are under the purview of three companies — Dominion, ES&amp;S and Hart InterCivic.Many of the products they make have documented vulnerabilities and can be subverted in multiple ways. Hackers can access voting machines via the cellular modems used to transmit unofficial results at the end of an election, or subvert back-end election-management systems — used to program the voting machines and tally votes — and spread malicious code to voting machines through them. Attackers could design their code to bypass pre-election testing and kick in only at the end of an election or under specific conditions — say, when a certain candidate appears to be losing — and erase itself afterward to avoid detection. And they could make it produce election results with wide margins to avoid triggering automatic manual recounts in states that require them when results are close.Hackers could also target voting-machine vendors and use this trusted channel to distribute their code. Last year a security researcher stumbled across an unsecured ES&amp;S server that left passwords exposed for its employee accounts. Although the passwords were encrypted, a nation-state with sufficient resources would most likely be able to crack them, the researcher noted. Since ES&amp;S creates ballot-definition files before each election for some customers — the critical programming files that tell machines how to apportion votes based on a voter’s screen touch or marks on a paper ballot — a malicious actor able to get into ES&amp;S’s network could conceivably corrupt these files so machines misinterpret a vote for Donald Trump, say, as one for his opponent, or vice versa.Did anything like that happen in 2016? The Department of Homeland Security, the intelligence community and election officials have all insisted that there is no evidence that Russian hackers altered votes in 2016. But the truth is that no one has really looked for evidence. Intelligence assessments are based on signals intelligence — spying on Russian communications and computers for chatter or activity indicating that they altered votes — not on a forensic examination of voting machines and election networks. “We should always be careful to point out that there hasn’t been any evidence that votes were changed in any election in this way, and that’s a true fact,” said Matt Blaze, a computer-science professor at the University of Pennsylvania and a voting-machine-security expert. “It’s just less comforting than it might sound at first glance, because we haven’t looked very hard.” Even if experts were to look, it’s not clear what they would find, he added. “It’s possible to do a pretty good job of erasing all the forensic evidence.”And targeting voting machines is just one way to subvert elections. A hacker (or inside operator) could target voters themselves by deleting their names from the voter roll and electronic poll book — the device used at polling places to verify a voter’s eligibility. Or change their precinct assignments to send them to the wrong location, creating chaos and frustration that causes them to leave without voting. Bad actors could also undermine election results by altering tallies as they are transmitted to county offices on election night or posted to public websites. Although these are unofficial results, any discrepancy between these and official tallies compiled days after an election would sow distrust in the outcome, particularly if the winner of a race changes.The stakes are high when it comes to election security, and the concerns about Russian hackers are warranted. But the focus on Russia, or any would-be election manipulators, ignores the underlying issue — the myriad vulnerabilities that riddle the system and the ill-considered decisions that got us here. The mad history of election security in the United States is a history of how misguided politicians and naïve election officials allowed an unregulated industry to seize control of America’s democratic infrastructure.[Read about Amendment 4, the ballot that could enfranchise more people at once than any single initiative since women’s suffrage, but could also change the Florida electorate.] The ballot box is in the distressed state it is in today because of an overreaction — or rather a wrong reaction — to a previous systemic electoral breakdown: the presidential-election fiasco in Florida in 2000. Everyone remembers the dangling chads that led to a landmark Supreme Court decision and a nation divided over who won. But another election mishap occurred that night that got less attention, despite the fact that it played a significant role in pushing the presidential race into the hands of the justices. This one involved a memory card in Volusia County.Deborah Tannenbaum had a front-row seat for what occurred that night. A Democratic Party field director in Florida, she refreshed her web browser frequently as returns came in from around the county. At 10 p.m., Al Gore was ahead in Volusia, with 83,000 votes to George W. Bush’s 62,000. Things were going well for Gore across the state, and exit polls projected a six-point lead for him. But then something changed. “I had stepped out, and one of the assistants came, and he’s just like, ‘I need you to come here and verify the numbers,’ ” Tannenbaum recalled. When she looked at the county’s website, Gore’s total had dropped 16,000 votes. Tannenbaum called the county election office, alarmed. “I don’t know what’s going on down there, but you can’t take away votes!” she said.The mysterious drop would later be traced to Precinct 216, a community center in DeLand, where Gore’s total was showing negative 16,022 votes. It wasn’t the only mathematical absurdity in the tally. A Socialist Workers Party candidate named James Harris had 9,888 votes. But the DeLand precinct had only 585 registered voters, and only 219 of them cast ballots at the center that day.Unfortunately for Gore, reporters were focused on overall state returns and didn’t notice the funny numbers. At 7:52 p.m., Voter News Service — a consortium of media outlets reporting election results — projected Gore the Florida winner based on exit polls. But when the Volusia County numbers changed at 10 p.m., and Brevard County subsequently posted results inadvertently missing 4,000 votes for Gore, Bush shot into the lead; news outlets retracted their call for Gore and called the state for Bush. Gore was on his way to make a concession speech at 3 a.m. when he learned the numbers were wrong.Volusia officials blamed the mishap on a faulty memory card. The county used optical-scan machines made by Global Election Systems (a Canadian company later acquired by Diebold and renamed Diebold Election Systems), which the county had used since 1996. When the election ended, poll workers were supposed to transmit results to the county election office via modem; but the transmission failed, so a worker drove the memory card in, where officials inserted it directly into the election-management system to tally results. Logs for that computer, however, showed two memory cards for Precinct 216 inserted, an hour apart. The vote totals went haywire after the second card was loaded.Beyond the mystery of the two cards, there was another problem with this explanation. A faulty memory card should produce an onscreen error message or cause a computer to lock up, not alter votes in one race while leaving others untouched. And what kind of faulty card deleted votes only for Gore, while adding votes to other candidates?Ultimately, the phantom card was forgotten in the battle that ensued over dangling chads in other counties. Gore’s team requested manual recounts in four counties, including Volusia, but a Supreme Court ruling on Dec. 12 halted them, though not before Volusia completed its recount. The manual tally of optical-scan ballots in Precinct 216 gave Gore 193 votes, Bush 22 and Harris 0. Bush won Florida, and by extension the presidency, by just 537 votes.To this day, questions about the Volusia card remain unanswered. Internal emails from Global Election Systems later leaked to Bev Harris, an election-integrity activist, show that the manufacturer itself remained unsure about what happened. When a Volusia County elections worker named Lana Hires requested an explanation from Global, the response was vague. Talbot Iredale, a Global developer, responded that a corrupt memory card remained “the most likely explanation for the problem but since I know nothing about the ‘second’ memory card I have no ability to confirm the probability of this.” He then suggested a more ominous explanation. “There is always the possibility that the ‘second memory card’ or ‘second upload’ came from an unauthorized source.” To which a Global colleague replied: “Heh. Second shooter theory. All we need now is a grassy knoll.”The memory card in Volusia vividly demonstrated the kind of problems that could occur if states expanded their use of electronic voting machines without proper safeguards. But even as security experts showed how malicious insiders and outsiders could subvert the machines, the warnings went ignored.A month after the Supreme Court decision, Representative Steny Hoyer, a Maryland Democrat, met with Representative Bob Ney, an Ohio Republican and his colleague on the House Administration Committee, to talk about election reform. Hoyer wanted to make sure that what happened with Florida’s punch cards didn’t happen again. So, unmindful of the lessons of Volusia County, they decided to draft a bill that would push states to get rid of punch-card systems as well as lever voting machines, a century-old mechanical technology still being used in some states, and replace them with new electronic voting systems. But beyond setting parameters to protect civil rights and prevent disenfranchisement, the federal government couldn’t tell states how to run elections.So Hoyer and Ney devised a workaround: money. Their bill, the Help America Vote Act, or HAVA, offered states $3.9 billion to help administer federal elections and buy new voting equipment. But the money came with a few conditions: States couldn’t spend it on punch-card or lever machines, and if they wanted to use HAVA funds to replace these systems, they had to do so in time for the 2004 presidential elections (or by 2006 if they sought an extension). They also had to offer at least one accessible voting machine at each polling place so that disabled voters could cast ballots without assistance. And they had to consolidate county voter-registration files into a single statewide database to prevent voters from registering in multiple counties. HAVA also created a new agency — the U.S. Election Assistance Commission — to administer the funds to states and to serve as a clearinghouse for election best practices.Computers had been used in elections ever since the 1960s, when punch cards and computerized card readers and tabulators were introduced. And experts had been warning for just as long about the danger of placing too much trust in them. A 1969 front-page article in The Los Angeles Times described a “war games” exercise to determine if Los Angeles County’s new computerized punch-card readers and tabulators could be rigged without detection. Three computer scientists on the offensive team faced off against three computer scientists on defense. “In each test, the offensive team won,” the paper reported; the team’s “highly sophisticated techniques” were neither detected nor prevented. The importance of paper ballots to back up and verify digital vote tallies was also underscored by numerous election mishaps over the years. In Rock Island County, Ill., in 1984, for every one vote cast for a particular candidate, a computer tabulator gave him two; it also failed to count “no” votes on a referendum. In Moline, Ill., in 1985, a punch-card reader elected the wrong candidate for City Council by failing to properly count some votes; a recount flipped the race.Hoyer insists that the subject of security and paper trails didn’t come up when lawmakers were developing HAVA. But Rebecca Mercuri disputes this. A computer scientist at Bryn Mawr at the time, she told the House science committee — in a hearing that was meant to inform the lawmakers writing HAVA — that “any programmer can write code that displays one thing on the screen, records something else and prints out something else as an entirely different result. I have freshmen, by the way, who can do this. There is no known way to ensure that this is not happening inside of a voting system.”The experts also recognized even then that voting machines wouldn’t be secure if there weren’t adequate standards for testing and certifying them. Douglas W. Jones, a computer-science professor at the University of Iowa and the chairman of a board that tested and approved machines used in his state, testified to the science committee that the voting machines available to replace punch-card and lever machines weren’t secure, largely because the standards didn’t require them to be. The standards were created in the 1980s, when security was a nascent field and touch-screen D.R.E.s didn’t exist. He advised lawmakers against issuing large-scale funding for new machines until better standards and machines were available.But few in Congress took the critics seriously. Although lawmakers did include a provision in HAVA mandating the creation of new standards — with the aim that machines bought with HAVA funds would meet them — the purchasing deadlines they included in the bill forced states to buy their machines before the new standards could be completed in 2005 (they took effect in 2007). In October 2002, the bill passed with broad bipartisan support, and the clock began ticking down to the November 2004 deadline to replace punch-card machines.And with that, the gold rush was on, as a small group of vendors with little security expertise began lining up to win billions of dollars of federal money. Most of that money ended up going to buy D.R.E.s. In 2000, just 9 percent of American voting precincts were using D.R.E.s. After HAVA passed, the proportion ballooned to 67 percent. The basic technology was not new; the first direct-recording electronic voting machines went on sale in 1974, and touch-screen versions were introduced in the mid-90s. But before HAVA, election officials who wanted electronic machines generally chose optical-scan systems. Each machine was more expensive, but you needed fewer per polling place, because voters could fill out the ballots in simple booths and then quickly scan them.The new D.R.E. machines did offer real advantages. With direct recording, counties no longer had to print hundreds of thousands of paper ballots or store them for 22 months after a federal election, as federal law required. And the machines could be adapted to voter needs, by displaying digital ballots in multiple languages and font sizes. They also satisfied the accessibility requirement in HAVA, offering Braille keyboards, audio instruction and other aids for physically impaired voters.Under HAVA, states had to purchase only one accessible machine per precinct and could provide optical-scan systems for other voters. But some counties bought D.R.E.s exclusively, swayed in part by the National Federation of the Blind, which insisted that HAVA, in calling for “uniform and nondiscriminatory election technology,” required states to provide identical equipment for all voters. This interpretation benefited vendors, of course, who were more than happy to sell counties their most expensive systems.In November 2002, just days after Bush signed HAVA into law, Georgia underwent the nation’s first major test of D.R.E.s. The state had signed a $54 million contract with Diebold to use its paperless D.R.E.s exclusively statewide. As the November midterm elections approached, the company scrambled to get the machines in place for one of the closest races for governor that Georgia had seen — between Gov. Roy Barnes, a Democrat, and his Republican challenger, Sonny Perdue. Perdue won with just 51 percent of votes in a major upset. It was the first time in more than 130 years that a Republican became governor of Georgia. This wasn’t the only upset. Senator Max Cleland, a popular Democrat, went into Election Day leading his Republican opponent, Saxby Chambliss, by three points; he lost by seven.What happened next highlighted everything that was wrong with electronic voting machines and their vendors. Rob Behler, a contractor who worked in the Georgia warehouse where Diebold prepared its D.R.E.s for the election, came forward to reveal that many of the machines experienced frequent crashes or other persistent malfunctions. Diebold had given workers at least three software patches to fix the problems, he said, but the patches were not examined by the independent lab responsible for testing voting machines or by Georgia officials. Brit Williams, a retired academic overseeing the rollout for the state, denied to me at the time that Diebold installed any uncertified patches, but acknowledged that it did install one patch that a test lab took a “quick look” at.The Georgia patches underscored a disturbing reality — no one really knew what companies were programming into their black boxes, in part because the lab testing reports were confidential. Election activists and computer-security experts did get occasional glances inside the boxes, though, and what they saw wasn’t reassuring. Months after the Georgia election, Bev Harris, the election-integrity activist, discovered the FTP server that Diebold used to distribute software patches for its machines in Georgia. The server had been left unsecured, and Harris found about 40,000 files on it, including source code for Diebold’s D.R.E.s. She gave the code to computer scientists at Johns Hopkins University, who found several security problems with it, including an encryption key hard-coded in the software, a violation of basic security practices. The key was used to encrypt vote records and audit logs — the most critical data on a voting system — and was the same key for every Diebold system. Anyone who accessed the source code on Diebold’s unsecured server could find the key in the code.Over the next several years, reports commissioned by officials in California, Maryland and Ohio found more problems with Diebold machines and similar issues with machines from other manufacturers. Problems with voting machines in elections were also making headlines. In 2002 in North Carolina, for example, D.R.E.s made by ES&amp;S failed to record 436 entire ballots during early voting in Wake County, a failure the company attributed to a software bug. Two years later, in Jacksonville, N.C., a D.R.E. made by UniLect lost more than 4,500 ballots when its memory became full and stopped recording; it continued to let voters cast ballots, however, instead of locking up. The incidents that made headlines were disturbing enough, but the real concerns were the ones that weren’t being caught.The problems with voting machines did not go entirely unnoticed on Capitol Hill. In May 2003, Representative Rush Holt, a New Jersey Democrat, introduced an amendment to HAVA that would require all voting machines to produce a voter-verifiable paper trail and to mandate random manual audits. It was an opportunity for lawmakers like Hoyer, who missed the security issues with D.R.E.s the first time, to make up for the oversight. But still they resisted. Hoyer told me, “I didn’t think Rush was correct” about paper trails. Hoyer and other lawmakers believed that the new voting systems were “in fact reliable and secure and user-friendly. Now I think in retrospect we were obviously wrong, because our premise was the machines were not subject to being hacked. And now we know.”The troublesome 2004 presidential election in Ohio, in which Kerry was denied access to the voting software, provided a strong case for why paper and audits were necessary. A lot of Ohio counties still used punch cards, but some had adopted D.R.E.s and optical-scan systems. For one precinct of Franklin County, which used D.R.E.s made by a company called Danaher Control, the election-management system tallied 4,258 votes for Bush, though only 638 voters cast ballots. When officials pulled votes stored in the D.R.E., Bush’s total was 365. In Mahoning County, voters using 25 D.R.E.s made by ES&amp;S found that when they touched the screens to vote for John Kerry, the machines interpreted it as a vote for Bush, not an uncommon problem when touch screens are poorly calibrated. “Undervoting” — when a ballot shows no vote in a particular race — was also exceptionally high in the state. Democratic precincts across Ohio had 75 percent more undervotes than predominantly Republican ones. In two precincts in Montgomery County that used punch-card machines, the computer tabulators indicated that 6,000 ballots had no vote for president — an undervote rate of 25 percent, while 2 percent is normal. A congressional inquiry found “numerous serious election irregularities” in Ohio but ultimately couldn’t conclude whether fraud had occurred.The incidents in Ohio demonstrated that American elections still had integrity problems, but there was little constituency for change. In 2005, Holt introduced a variation of his 2003 reform bill, and once again it quickly died, in part because voting-machine vendors launched a formidable lobbying effort to quash the requirement of paper trails. Some state election officials joined the effort, arguing that adding printers to D.R.E.s would create problems for elderly poll workers if the printers jammed or ran out of paper. The American Association of People With Disabilities was also remarkably effective in lobbying against paper trails, arguing that they discriminated against blind voters, even though the same audio that assisted blind voters to mark their digital ballot could read the paper trail to them. The association persuaded the League of Women Voters and the American Civil Liberties Union, two politically powerful groups, to oppose paper trails as well.A second major undervote incident with D.R.E.s in 2006 also failed to move Congress. In Sarasota, Fla., more than 18,000 ballots cast on D.R.E.s made by ES&amp;S showed no vote in the race for the 13th Congressional District. Kathy Dent, the supervisor of elections, insisted that voters either didn’t see that particular contest or intended to leave it blank. But documents I obtained through a public-records request showed that poll workers in 19 precincts called her office on Election Day and during the primary months before it to pass along voter complaints about the machines. Many reported that when they tried to vote for Christine Jennings, a Democrat, the screen failed to register their touch. Jennings lost by fewer than 400 votes. The incident led Florida — the state whose punch-card fiasco prompted the nationwide switch to paperless D.R.E.s — to mandate the use of voter-marked paper ballots. But when Holt reintroduced his bill in Congress in 2007 and 2009 to do the same, he still couldn’t get any interest.Despite this proliferation of voting-machine problems, the industry was expanding its reach and control, even as it was concentrating power into fewer hands. By 2010, ES&amp;S was so big — it had bought Diebold’s election division and controlled more than 70 percent of the market — that the Justice Department filed an antitrust suit and required it to sell off some of its assets. Many election officials, baffled by the new technology and unable to hire dedicated I.T. staff, purchased complete suites of election services from vendors, services that in some cases included programming ballot-definition files for voting machines and assisting with tabulation. It became common to see voting-machine employees or their local contractors in election offices before, during and after elections, and in some cases even working in election offices full time. ES&amp;S, for instance, even installed remote-access software and modems on election-management systems to gain remote access to them from its Nebraska headquarters to troubleshoot when things went wrong. And when things did go wrong with machines, it was often the vendor who investigated and supplied the explanation that was fed to the news media and the public.The companies also expanded their reach into other parts of the elections process. Some states built their HAVA-mandated voter-registration databases in-house, but some outsourced this to Diebold and ES&amp;S, the companies that made their voting machines, as well as to other firms. And once these centralized databases were in place, the vendors saw an opportunity for another revenue stream: They persuaded states to replace paper poll books — the lists poll workers use to verify that voters are registered — with electronic poll books that could sync with the statewide databases. The software on these devices didn’t have to undergo testing and certification the way voting machines do, and there were inevitable problems — in 2006 in Denver, Sequoia electronic poll books crashed extensively, creating long lines for an estimated 20,000 people who left without voting. In 2008 in Georgia, Diebold electronic poll books caused delays lasting more than two hours.Over the years, as election officials became more comfortable with their voting equipment, many jurisdictions who gave control to vendors gradually took it back, but there are still districts where vendors and contractors are involved in every phase of elections, from writing the software that registers voters and determines their eligibility to cast ballots, to programming machines and counting the votes. And it’s not clear to what degree, if any, they’re subject to oversight.Sixteen years ago, lawmakers led Americans to believe that they had solved the problems of Florida in 2000. But the 2016 election made it clear that the problems simply shifted from one technology to another. Once again, lawmakers are proposing fixes that they say will help address the current state of elections, and once again, those proposals fall short.Legislators have introduced several bills that propose to bolster security, in part by mandating paper trails and manual audits. But only one of them, the Secure Elections Act, has advanced, and in the process it has been significantly watered down. In August, Republican lawmakers weakened the bill by allowing officials performing audits to rely on the digital images of paper ballots stored in optical-scan machines — images that can be manipulated by hackers and others, security experts say.This year, Congress appropriated $380 million to states to pay for security upgrades and replace some of the machines that were bought with HAVA funds more than a decade ago, in the belief that this will make elections more secure. But the new machines have the same problems as the ones they will replace — all machines on the market today were tested and certified to the standards HAVA put into effect in 2007, and technology has evolved considerably in the last decade. The Election Assistance Commission and its technical-guidelines committee are completing new standards, but it will be at least another two years before any machines will be tested and certified to them.Even those standards will almost certainly be inadequate. They will, for instance, most likely continue to exempt commercial off-the-shelf components from testing. (If a vendor uses the Windows operating system or a commercial modem in its machines and asserts that it hasn’t altered them, the labs don’t look at those components.) And they probably won’t require labs to do “penetration testing” to see if they can hack voting systems — one of the most effective ways to measure the security of a system. “These companies have seized a central role in our democracy,” said Senator Ron Wyden, an Oregon Democrat who is one of a small group of lawmakers who have shown a willingness to demand more transparency from the vendors. “But rather than recognizing that cybersecurity needs to be their top priority, they treat it as a public-relations problem that can be dismissed with spin.”The valuable work of testing system security has been taken up voluntarily by security researchers like the Finnish computer programmer Harri Hursti, J. Alex Halderman of the University of Michigan and the participants at the recent Def Con Voting Machine Hacking Village. But the researchers face hostility and sometimes even legal threats from vendors, who want to prevent them from finding and exposing problems with the machines. Before the Def Con event this year, which received unprecedented support and interest from election officials, ES&amp;S and other vendors sent comments to the United States Copyright Office expressing opposition to a proposed exemption to the Digital Millennium Copyright Act that would expand the rights of researchers to reverse-engineer election software.Even now, when the country is desperate to prevent Russian hackers from interfering with future elections, the company is more focused on asserting proprietary control over its systems than on working with communities of researchers who want to secure them. In addition to the comments it sent the Copyright Office, it also sent a vaguely threatening letter to its own customers, warning them against helping researchers by providing them with voting-machine software to examine. In that letter, ES&amp;S reminded election officials of an essential fact: The American people don’t own the software that now sits at the heart of their democracy; they just lease it.An earlier version of this article referred imprecisely to an area in Ohio where 638 voters cast ballots in the presidential election of 2004. It was in one precinct in Franklin County, not the county as a whole.Kim Zetter has covered cybersecurity for more than a decade. She is the author of “Countdown to Zero Day: Stuxnet and the Launch of the World’s First Digital Weapon.”

Supported byThe network must be secure enough for the innovations it promises.By Tom WheelerMr. Wheeler is a former chairman of the Federal Communications Commission.The Trump administration’s so-called “race” with China to build new fifth-generation (5G) wireless networks is speeding toward a network vulnerable to Chinese (and other) cyberattacks. So far, the Trump administration has focused on blocking Chinese companies from being a part of the network, but these efforts are far from sufficient. We cannot allow the hype about 5G to overshadow the absolute necessity that it be secure.Our current wireless networks are fourth-generation, or 4G. It was 4G that gave us the smartphone. Reaching the next level of mobile services, however, requires increased speed on the network. Fifth-generation networks are designed to be 10 to 100 times faster than today’s typical wireless connection with much lower latency (response time). These speeds will open up all kinds of new functional possibilities. Those new functions, in turn, will attract cyberintrusions just like honey attracts a bear.Some envision 5G as a kind of “wireless fiber” for the delivery of television and internet much like a cable system does today. Iranians hacking the delivery of “Game of Thrones” isn’t good, but the real transformational promise of 5G goes far beyond wireless cable and its security is much more critical.The most exciting part of the 5G future is how its speed will change the very nature of the internet. Thus far, the internet has been all about transporting data from point A to point B. Today’s internet-connected car may be able to get driving directions sent to it, but it is essentially the same as getting email: the one-way transportation of pre-existing information. The autonomous car is something vastly different, in which the 5G network allows computers to orchestrate a flood of information from multitudes of input sensors for real time, on-the-fly decision-making. It is estimated that the data output of a single autonomous vehicle in one day will be equal to today’s daily data output of three thousand people.Leadership in 5G technology is not just about building a network, but also about whether that network will be secure enough for the innovations it promises. And the 5G “race” is more complex and dangerous than industry and the Trump administration portray. When 5G enables autonomous vehicles, do we want those cars and trucks crashing into each other because the Russians hacked the network? If 5G will be the backbone of breakthroughs such as remote surgery, should that network be vulnerable to the North Koreans breaking into a surgical procedure? Innovators, investors and users need confidence in the network’s cybersecurity if its much-heralded promise is to be realized.“It is imperative that America be first in fifth-generation (5G) wireless technologies,” President Trump wrote in an October Presidential Memorandum of instructions to federal agencies. While the administration, especially the Trump Federal Communications Commission (F.C.C.), makes much of how the 5G “race” with China is a matter of national security, not enough effort is being put into the security of the network itself. Nowhere in the president’s directive, for instance, was there a word about protecting the cybersecurity of the new network.As the President’s National Security Telecommunications Advisory Committee told him in November, “the cybersecurity threat now poses an existential threat to the future of the Nation.” Last January, the brightest technical minds in the intelligence community, working with the White House National Security Council (N.S.C.), warned of the 5G cybersecurity threat. When the proposed solutions included security through a federally-owned network backbone, the wireless industry screamed in protest. The chairman of the Trump F.C.C. quickly echoed the industry line that “the market, not government, is best positioned to drive innovation and leadership.” Government ownership may not be practicable, but the concerns in the N.S.C. report have been dismissed too readily.Worse than ignoring the warnings, the Trump administration has repealed existing protections. Shortly after taking office, the Trump F.C.C. removed a requirement imposed by the Obama F.C.C. that the 5G technical standard must be designed from the outset to withstand cyberattacks. For the first time in history, cybersecurity was being required as a forethought in the design of a new network standard — until the Trump F.C.C. repealed it. The Trump F.C.C. also canceled a formal inquiry seeking input from the country’s best technical minds about 5G security, retracted an Obama-era F.C.C. white paper about reducing cyberthreats, and questioned whether the agency had any responsibility for the cybersecurity of the networks they are entrusted with overseeing.The simple fact is that our wireless networks are not as secure as they could be because they weren’t designed to withstand the kinds of cyberattacks that are now common. This isn’t the fault of the companies that built the networks, but a reflection that when the standards for the current fourth-generation (4G) technology were set years ago, cyberattacks were not a front-and-center concern.The Trump administration has been told that cybersecurity is an “existential risk.” The new Congress should use its oversight power to explore just why the administration has failed to protect against that risk, especially when it comes to the next generation of networks.Tom Wheeler, the chairman of the Federal Communications Commission from 2013 to 2017, is a visiting fellow at the Brookings Institution and a fellow at the Harvard Kennedy School. His new book, “From Gutenberg to Google: The History of Our Future,” will be published in February.Follow The New York Times Opinion section on Facebook, Twitter (@NYTopinion) and Instagram.

Supported byWheelsBy Jim MotavalliGoing back at least a decade, cars have been targeted by hackers, some who ended up working with the industry, others acting maliciously. But vehicles now carry far more electronic equipment, and autonomous driving, relying on sensors, cameras and radar, is on the horizon, with all kinds of ripe new targets.Concern that cars could be seriously hacked — by criminals, terrorists or even rogue governments — has prompted a new round of security efforts on the part of the auto industry.As far back as 2010, a disgruntled former employee at Texas Auto Center in Austin used a co-worker’s account to log into company software used for car repossession. He disabled over 100 cars, and owners who were up to date on their payments suddenly found their vehicles honking furiously, and unable to start.In 2015, a veteran hacker named Samy Kamkar built a device for under $100 that he said could find, unlock and remotely start any General Motors car equipped with the OnStar communications system. Luckily, Mr. Kamkar was acting as a “white hat,” and not selling his OwnStar device to unscrupulous hackers.“I worked with G.M. to resolve that issue,” he said, and that particular vulnerability is gone. “Cars are getting more secure, but it’s a long cycle to get the necessary new software and hardware installed.”Dan Flores, a G.M. cybersecurity and safety spokesman, confirmed the collaboration with Mr. Kamkar. “We recognize the importance of the work that researchers, like Samy, do to help advance the work in this area,” he said in an email.Securing cars is a big challenge, which is why some companies that traditionally prefer to go it alone have teamed up to share best practices.Digital threats to self-driving cars, according to a 2018 University of Michigan report, “include hackers who would try to take control over or shut down a vehicle, criminals who could try to ransom a vehicle or its passengers and thieves who would direct a self-driving car to relocate itself to the local chop-shop.”The average car has over 150 million lines of computer code, and some have even more than a Boeing 787, according to a 2018 KPMG report. That complexity, the report said, “creates a real risk of cyberattack — a risk we fear many companies in the automotive industry may be underestimating.”That view is widespread. “From my perspective, automakers were a little surprised and caught off guard by this threat,” said Doug Newcomb, a senior industry analyst at Wards Intelligence. “They added all this connectivity, but got ahead of themselves and don’t always think of the vulnerabilities that exist. It’s an ongoing issue, not a fix-it-and-forget-it thing.”Failing to protect consumers can be costly, said Steve Tengler, a principal at the consulting company Kugler Maag Cie who has worked at Ford, Nissan and G.M., and was a senior director of connected vehicle cybersecurity at Honeywell.Automakers are legally bound to provide state-of-the-art protection for their cars, Mr. Tengler said. “Legal precedents show that it’s not enough to provide a product that is kind of safe,” he said. “Companies don’t have to put themselves out of business to provide the safest technology, but they do have to work within their commercial ability.”Mr. Tengler said the industry was a frequent target. “Every automaker has been hacked — every one of them,” he said. “Attacks aren’t a matter of if, but when and how.”Once a car is out of warranty, automakers are used to cutting or at least loosening their ties. But hacking issues mean that protection will most likely require factory-to-junkyard monitoring.In 2015, Fiat Chrysler recalled 1.4 million cars and trucks after Chris Valasek and Charlie Miller demonstrated, in a Wired magazine article, that they could remotely control a Jeep Cherokee’s brakes, radio, wipers and other functions by gaining access through its UConnect infotainment system.The company declined to comment on any subsequent security changes.Dr. André Weimerskirch, vice president for cybersecurity and functional safety at Lear Corporation, said that automakers had made “huge improvements” in recent years, and that joint efforts involving the industry, academia and standards organizations had also led to gains.Most car hackers have been wearing those white hats, with no criminal intent, but imagining what could happen led to the 2015 formation of the Automotive Information Sharing and Analysis Center, known as Auto-ISAC. Most of the world’s automakers are members.Faye Francy, the center’s executive director, described the Jeep episode as “a good wake-up call for the industry.”“The hackers are smart guys, very educated,” she said. “It’s not simple to do what they did. We’re fortunate that there hasn’t been another breach, but it’s not impossible.”Not impossible, but still difficult. Ron Plesco, a principal at KPMG Cyber Security Services, agrees that hacking into a car’s driver controls requires “a lot of knowledge and effort.”“It’s not as easy as Hollywood claims it is,” he said.That’s one reason we haven’t seen more major attacks. But Mr. Plesco argues that today there isn’t much incentive for thieves, since the identity information stored onboard vehicles is fairly limited.“But,” he added, “that’s about to change as we do more purchasing through the dashboard of the car. The automobile is becoming another computer that can be hacked.”New infotainment and autonomous features are important selling points, but because most consumers assume their cars are safe, automakers tend to keep cybersecurity news in the background. Much is happening behind the curtain, however. Some private security firms say they are signing on with major automakers to provide expert protection.“There are multiple ways for hackers to get in, and it’s the job of the whole industry to defend against it,” said Dan Sahar, a vice president at Upstream Security in Israel. “Just one hack can cost a manufacturer tens of millions of dollars, and that doesn’t include the brand damage. And the threat is getting more serious.”According to Mr. Sahar, “2018 saw more than 60 documented automotive-related cybersecurity incidents, a sixfold increase in just four years.”Upstream is working with “a handful” of manufacturers, Mr. Sahar said. “Automakers are focused on cybersecurity, but few say they can do it on their own,” he said.A 2019 Upstream report extrapolates a cost topping $1.1 billion for a breach that requires a large recall. The opportunity will certainly be there for criminal hackers. Juniper Research of Britain estimated in a 2018 report that by 2023 some 775 million cars would be connected to the web in some way (up from 330 million in 2018).Mr. Tengler, of Kugler Maag Cie, said it was easy to picture the danger that hackers posed to autonomous vehicles — potentially redirecting them as part of a theft. But the Jeep hack proved “it doesn’t matter if someone is driving,” he said. “If they can take control of the car, the vulnerable technology is already there.”Thieves have stolen cars by using fairly simple electronic technology, some of it freely available. A device that amplifies the signals from a car’s remote can be used to unlock the target vehicle’s doors. Mr. Kamkar said he had built such devices from off-the-shelf components for approximately $50.“It’s a lot simpler than people think,” he said.Other devices include a radio transmitter that cycles through huge numbers of possible combinations until they “crack” the target car’s key fob. In 2006, that was reportedly how the soccer star David Beckham’s armor-plated BMW X5 was stolen in Madrid. A second X5 belonging to Mr. Beckham was also stolen.“Car thieves used to have crowbars; now they use laptops,” said Mr. Plesco at KPMG.Jono Anderson, also a principal at KPMG, said the auto industry needed to learn from aerospace.“They’re very familiar with this kind of security,” Mr. Anderson said, “but it’s new to the auto industry. Maybe it’s possible to hack the entertainment system in a plane and get free movies, but it’s virtually impossible to hack the actual communications.”

Supported byBy Marc SantoraPRAGUE — In an attempt to push back against attempts to limit its reach in Europe, the Chinese technology giant Huawei threatened legal action against the Czech Republic if its cybersecurity agency did not rescind its warning about the risk the company poses to the nation’s critical infrastructure.As nations across Europe take the first steps to reconfigure the systems that control the internet, Huawei’s threat was the latest salvo in the escalating war over who will control the hardware that will underpin the new 5G, or fifth-generation, networks.For more than a year, the United States has been engaged in a global campaign aimed at limiting the reach of Chinese telecommunication firms, contending that they pose a threat to security.While American officials have not offered specific details to support their concerns, they have pointed to China’s National Intelligence Law, passed in 2017. They say the law requires Chinese companies to support, provide assistance to and cooperate in Beijing’s national intelligence work, wherever they operate.That law was one of the factors that led the Czech cybersecurity agency, Nukib, to issue a formal warning in December about the risk posed by Huawei and another Chinese technology firm, ZTE.The warning, which carries the force of law, requires all companies in the Czech Republic that are deemed critical to the nation’s health to perform a risk analysis that takes security concerns into account.It has already led several large companies and government ministries to distance themselves from Huawei, including barring the company from bidding on new projects.On Friday, the Czech newspaper Dennik N published excerpts from a letter from Huawei to the head of the Czech cyber agency, Dusan Navratil, and Prime Minister Andrej Babis threatening legal action.“Huawei cannot represent a cybersecurity threat as stated in the warning,” the letter said. “Huawei, according to the Chinese law, does not have any obligation to install backdoor or spyware into their products, and the company would never agree to such a request.”Radoslaw Kedzia, Huawei’s chief representative in the Czech Republic, wrote that the cyber agency had failed to provide any specific evidence of wrongdoing and failed to explain its analysis of the Chinese law.“As consequence of the warning, Huawei has already suffered losses and faces many difficulties,” he wrote in the letter, dated Feb. 1. “For example, it was excluded from public procurement, even those that do not concern critical infrastructure.”“Retail activities have been harmed and the brand damaged,” according to the letter. The company called on Czech officials to rescind the warning, adding that if they did not receive a reply by Feb. 14, they would take the matter to court.Officials at the cybersecurity agency acknowledged receipt of the letter, a copy of which was obtained by The New York Times, but declined to comment.The pushback by Huawei was part of a broader campaign by the company to defend itself across the continent.Huawei sent a letter to the British Parliament this week defending its track record and claiming that any malicious activity on its part would “destroy its business.”The embattled company, which was founded by a former engineer in China’s People’s Liberation Army, claimed that the attacks against it were unfounded.“The governments in some countries have labeled Huawei as a security threat, but they have never substantiated these allegations with solid evidence,” Ryan Ding, the president of Huawei’s carrier business, wrote in the letter to the British lawmakers.The United States, Australia and New Zealand have already barred the company from participating in the building of the new 5G networks.In the coming months, countries across Europe are expected to begin to put in place infrastructure that would allow for the superfast, widely connected networks.Which companies will lead that effort remains an open question. But as Huawei’s threat of legal action demonstrates, the Chinese firm has no intention of ceding the lucrative market.Hana de Goeij contributed reporting.

Supported byBy Sam RobertsHoward A. Schmidt, a computer crime expert who advised two presidents and drafted cybersecurity safeguards that were approved by Congress in 2015, died on Thursday at his home in Muskego, Wis. He was 67.The cause was brain cancer, his wife, Raemarie, said.The legislation, which evolved from precautions Mr. Schmidt proposed several years earlier, enabled government and industry to share information about potential risks from attackers’ codes and techniques, shielded companies from liability lawsuits for trading data and provided privacy protections for consumers.By the time the legislation was finally approved, though, critics complained that it had been diluted in response to corporate concerns and was already technologically anachronistic.Recruited by President George W. Bush after the Sept. 11, 2001, terrorist attacks, Mr. Schmidt returned to the White House under President Barack Obama.He also oversaw the creation of the National Strategy for Trusted Identities in Cyberspace, an online authentication program less vulnerable than ordinary passwords to hackers engaged in identity theft or in stealing secrets from private industry or government.Mr. Schmidt won the trust of much of the business community, which was fending off a barrage of cyberattacks but which also feared government intrusion and a damper on innovation. At the same time, he suggested that the threat of full-scale cyberwarfare between governments was exaggerated and that any such conflict would be unwinnable.With the United States portraying itself as a victim of cyberwarfare and much of the world viewing Washington as a perpetrator — citing attacks on Iran’s nuclear program as examples — the White House proclaimed its first formal international cyberspace strategy during Mr. Schmidt’s tenure.That strategy mirrored the planned response to other security threats, in which the United States reserved the right to use all necessary diplomatic and military means to defend itself in the event of a hostile cyberincident. Meanwhile, Mr. Schmidt said, nations were already acting defensively.“Governments are starting to say, ‘In order to best protect my country, I need to find vulnerabilities in other countries,’ ” he told The New York Times in 2013. “The problem is that we all fundamentally become less secure.”He said hackers exploited the fear that if one buyer failed to pay for secret information about a computer coding flaw, another would.“If someone comes to you with a bug that could affect millions of devices and says, ‘You would be the only one to have this if you pay my fee,’ there will always be someone inclined to pay it,” he said. “Unfortunately, dancing with the devil in cyberspace has been pretty common.”For much of his 40-year career, Mr. Schmidt was in the forefront of information technology and computer security for the military, government agencies and private industry. Most recently he was a partner with Tom Ridge, the former Homeland Security secretary, in Ridge Schmidt Cyber, a security consultancy.In the mid-1990s, while working for the Air Force Office of Special Investigations, Mr. Schmidt was credited with helping to establish the federal government’s first full-time computer forensic laboratory. He also served as chief security officer at Microsoft and chief information security officer at eBay.Mr. Schmidt was the president’s special adviser for cyberspace security in the Bush administration from late 2001 to 2003. He was also chairman of the president’s Critical Infrastructure Protection Board.The Obama administration recruited him in late 2009 to be its computer security adviser. He reported to the National Security Council.Mr. Schmidt was the first president of the Information Security Forum, an industry and government coalition, and was chief security strategist for a partnership between the Department of Homeland Security and a cybersecurity program at Carnegie Mellon University in Pittsburgh.Howard Anthony Schmidt was born on Oct. 5, 1949, in Philadelphia to Anthony and Edith Schmidt. He served three tours in the Air Force in Vietnam from 1968 to 1974; was a police officer in Chandler, Ariz.; and worked for the F.B.I. at the National Drug Intelligence Center.He graduated from the University of Phoenix in 1994 with a bachelor of science degree in business administration and earned a master’s degree from that university.In addition to his wife, the former Raemarie Lange, a forensic scientist, Mr. Schmidt is survived by his mother, Edith Curtis; his stepmother, Gloria Schmidt; his sons, Kyle, David, Andrew and Anthony; and eight grandchildren.Read more obituaries and follow our coverage on Twitter.

Supported byThe skills needed for cybersecurity jobs aren’t easy to learn in the classroom.By Josephine WolffMs. Wolff is an assistant professor at the Rochester Institute of Technology.Between September 2017 and August 2018, employers in the United States posted 313,735 job openings for cybersecurity professionals. Filling those jobs would mean increasing the country’s current cybersecurity work force of 715,000 people by more than 40 percent, according to data presented at the National Initiative for Cybersecurity Education Conference this month. With the number of unfilled cybersecurity jobs worldwide projected to multiply into the millions in the next three years, it’s no surprise that governments, companies and schools are racing to pour more resources into cybersecurity training and education programs. As someone who teaches in a rapidly growing computing security program at the Rochester Institute of Technology, this is good news for me and my students. I think we are doing a good and responsible job of training our students, who will be snapped up by recruiters. But I’ve watched as the field of cybersecurity has become formalized through a flurry of new degrees, certificates and curriculums, and I worry that some fundamental components of what make people really good at security — namely, the instincts to look at systems in unconventional ways and quickly identify possible ways to cause trouble — are being lost along the way.The idea of degree programs focused solely on cybersecurity is still pretty new. At R.I.T., the bachelor’s degree in security was introduced in 2007, and the dedicated Computing Security department wasn’t formed until 2012. That means we haven’t had a lot of time to debug these programs, especially since, in academic settings, every significant curricular change typically requires several meetings followed by extensive paperwork and committee approval. The field is so new that nearly every cybersecurity professional over the age of 30 does not have a degree in cybersecurity — many of them don’t even have degrees in computer science, and several don’t have college degrees at all.Cybersecurity has long been a field that embraced people with nontraditional backgrounds. Following the Equifax breach last year, some critics slammed the company for hiring a chief security officer who majored in music, prompting a considerable backlash from security professionals who took to Twitter to flash their own liberal arts degrees or lack of formal education. The poster child for the unconventional path to a cybersecurity job is Kevin Mitnick, who was convicted of illegal computer hacking and spent five years in prison before establishing a career as a highly sought after security consultant.It’s not a coincidence that someone good at cybercrime would also be good at cybersecurity. After all, many cybersecurity jobs involve trying to think like a criminal to test the security of a software program, computer network or hardware device. Many of my students go on to work for red-teaming or penetration-testing firms, where they try to probe and attack computer systems from the outside to identify potential vulnerabilities. Some of these skills can be taught in the classroom, through checklists of where to look for possible weaknesses and tools that can be used to help conduct those assessments. But the most effective red teams, like the most effective attackers, find vulnerabilities that no one has ever thought of before — much less included on a course syllabus.The security technologist Bruce Schneier wrote an essay a decade ago about what he called “the security mind-set,” or the ability to instinctively identify ways of subverting or compromising systems by using them in unexpected ways. “It’s far easier to teach someone domain expertise — cryptography or software security or safecracking or document forgery — than it is to teach someone a security mind-set,” he wrote.Almost by definition, college classroom settings and the students who thrive in them are not a natural fit for the kinds of disruptive, rebellious and troublemaking instincts that lend themselves to finding new ways to compromise computers. It can be hard to reward those skills — much less teach them — in a college course where there are supposed to be clear expectations and learning objectives, well-defined grading rubrics and set schedules.There are efforts to try to introduce these skills to the classroom, but they are few and far between. For example, the security researchers Gregory Conti and James Caroland published an article on what they called “Kobayashi Maru” assignments, named for a “Star Trek” training exercise, designed to force students to figure out creative ways to cheat. The example they used in their own class was an exam for which students were required to write down the first 100 digits of pi with very little notice. The students were expected (and encouraged) to cheat on the test but told that if they were caught, they would fail the exam. Of the 20 students in the class where this exercise was tested, all succeeded in cheating without being caught, much to their professors’ delight.There is plenty of useful and important material being taught in cybersecurity classes beside how to cheat, from programming and networks to cryptography, and my own area of economics and policy. But the students who graduate from our degree program in security often report that they got more out of their extracurricular security clubs and competitions than their coursework. That may not necessarily be bad, or even unique to cybersecurity (don’t get me started on the topic of how much I learned writing for my college newspaper), but it does suggest that as we race forward trying to train millions more people in cybersecurity to fill all the looming vacant jobs, there may be real gaps in the skills we know how to teach. We should think carefully about the skills we need, about the rules and principles that we know how to teach and also about how to encourage students to break those rules and find ways around those principles.Josephine Wolff (@josephinecwolff) is an assistant professor at the Rochester Institute of Technology and the author of “You’ll See This Message When It Is Too Late: The Legal and Economic Aftermath of Cybersecurity Breaches.”Follow The New York Times Opinion section on Facebook, Twitter (@NYTopinion) and Instagram.

Supported byBy Paul Mozur, Daisuke Wakabayashi and Nick WingfieldSHANGHAI — Apple said Wednesday that it would open its first data center in China, joining a parade of technology companies responding to growing global demands to build facilities that store online data closer to customers.The move is a response to a strict new law in China that requires companies to store users’ data in the country. The new data center, in Guizhou, a province in southwest China, is part of a $1 billion investment in the province and will be operated in partnership with a local data management company, Apple said.The move is part of a worldwide trend regarding the security and sovereignty of digital data. Microsoft, Amazon and Facebook are among the big American technology companies plowing billions of dollars into building data centers in Germany, the Netherlands, France and other countries. While some of the expansion is for technical reasons — the online services operate faster when they are near customers — the companies are also reacting to growing pressure from European governments and customers to maintain some control over their data.As is the case with many laws, the digital security regulations approved last month in China were vaguely worded, leaving many foreign companies uncertain about which parts would be enforced and how. Already, Amazon, Microsoft and IBM have formed partnerships with Chinese companies to offer cloud computing services based in China. Apple, easily the most successful foreign technology company in China, had much to lose without a plan for its own data center in the country.Apple said in a statement Wednesday that the new center would keep “strong data privacy and security protections in place.” The company added that no back doors, meaning ways for the government or other organizations to get around Apple’s encryption protecting the data, would be created in its systems.“The addition of this data center will allow us to improve the speed and reliability of our products and services while also complying with newly passed regulations,” Apple said.China’s rules also call for security reviews and for users of messaging apps to register their real identities. The regulations are part of a Chinese industrial policy adopted to build local capabilities. For example, a government plan called Made in China 2025 names several industries, including robotics and electric cars, in which China hopes its companies will become leaders. Foreign business groups have said the laws unfairly discriminate against companies that are not Chinese.The iPhone is a symbol of middle-class ambitions in China and is the foundation of Apple’s business in the country, which accounts for 21 percent of the company’s global sales, making it Apple’s most important market after the United States.But the iPhone has also become emblematic of China’s long reliance on foreign technology. Even before China passed the cybersecurity law last year requiring that the online data of its citizen be stored domestically, the country was pressuring foreign technology companies to operate its computer servers within its borders.Apple already stores some of the data of China’s residents in local servers, but the new agreement goes one step further with a Chinese partner responsible for running its data center, managing the sales of its services in the country and handling legal requests for data from the government.In 2014, Apple first moved some of the data of its Chinese customers that had been overseas to a domestic plant operated by China Telecom. The change occurred shortly after state-run China Central Television raised security concerns that Apple was tracking the locations of iPhone users.Careful not to offend, Apple said it “appreciated” that CCTV had flagged the issue but explained that the company did not have access to its users’ locations.The opening date for the new data center has not been set, but when it does open, Apple’s iCloud will operate from an Apple plant run by Guizhou-Cloud Big Data Industry, a data management company. That means that if Apple customers in mainland China want to buy additional iCloud storage in the future, they will do so through Apple’s Chinese partner.Apple said, however, that it would retain the encryption keys for the data stored at its center and that Guizhou-Cloud Big Data would not have access, meaning it would not be able to see what photos or documents were stored in iCloud without Apple’s permission. This is the first time that Apple has formed a partnership with a local operator for its cloud services.Other American technology companies have also moved data into China in accordance with the new law. Airbnb said last year that it was moving its user data to a domestic location, citing a need to comply with local laws.Foreign companies like Apple have had to adapt in other ways to stronger Chinese government scrutiny, often by helping to expand Chinese technological capabilities. For instance, Apple said this year that it would establish two research and development centers in China. Last year, it invested $1 billion in Didi Chuxing, a Chinese ride-hailing service. Apple has been far more profitable in China than most of its Western peers, but that success has led to pushback from the government. More than a year ago, Apple’s iBooks Store and iTunes Movies were shut down in China, six months after they were introduced there.In December, complying with what it said was a request from the Chinese authorities, Apple removed news apps created by The New York Times from its app store in China. Apple did not specify what had prompted the request. The company also must undergo “security audits” on new models of the iPhone before gaining approval to sell them in China.Even though other American technology giants such as Facebook and Google are blocked in China, Apple has maintained a thriving business in the country by adhering to local rules. It also helps that Apple’s smartphones and computers do not carry the same political or security risks as social media platforms and networking equipment.Paul Mozur reported from Shanghai, Daisuke Wakabayashi from San Francisco and Nick Wingfield from Seattle.

Supported byBy Conrad De AenlleExchange-traded funds became the next big thing in portfolio management a couple of decades ago by being cheaper and easier to trade than mutual funds.These days, some managers are offering E.T.F.s as tools for specialization at the expense of diversification, carving up the stock market into ever thinner slices for investors eager to find other next big things.E.T.F.s have evolved from covering only broad indexes, such as the S&amp;P 500, to sectors like energy and health care, industries like homebuilding and gold mining, and lately to subsets of industries — niches within niches — often in ultracool areas like robotics, cybersecurity and video gaming that capture investors’ imaginations and then their money.While investment advisers occasionally use thematic funds when managing assets for their clients, they typically encourage small investors to avoid the practice, no matter how enticing it might be to try to find the next Amazon, Netflix or Google before it becomes a technological colossus.“We would prefer that someone build a portfolio around more diversified funds,” said Jason Browne, chief investment strategist of the FundX Investment Group, a firm that manages fund portfolios for high-net-worth individuals. He warned: “If you’re an average investor, you will probably look back and think this is something you were sold and not something thoughtfully invested in that’s aligned with your long-term goals.”Like Mr. Browne, Christopher Cordaro, chief investment officer of RegentAtlantic, a Morristown, N.J., financial-planning firm, said he sees more fund marketing than fund management at work with narrowly focused E.T.F.s.“It sort of reminds me of ‘The Graduate,’ when the guy takes Benjamin aside and says, ‘I’ve got one word: plastics,’” Mr. Cordaro said. Providers of these funds “are looking for things that sound good to people, then they give them an itch they’ll want to scratch.”Sam Masucci, chief executive of the ETF Managers Group, which manages about $3 billion across 12 thematic portfolios, said funds dedicated to such narrow market segments are especially dependent on investor demand and are introduced in areas experiencing a surge in popularity.His company’s thematic funds are a mix of actively managed and passively managed portfolios. In addition to cybersecurity and gaming funds, they cover some highly focused, even obscure, industries, including mobile payments and drone technology. And for anyone worried that all that cutting-edge technology will make human beings too efficient and productive, the company also offers the Alternative Harvest fund, which invests in companies involved in marijuana production.Anyone interested in these areas, despite admonitions like Mr. Browne’s, has several alternatives to choose from.A recent report on thematic E.T.F.s by Todd Rosenbluth, director of E.T.F. and mutual fund research at CFRA Research, highlighted two gaming funds — VanEck Vectors Video Gaming and eSports, and ETFMG Video Game Tech — and two that invest in cybersecurity: ETFMG Prime Cyber Security and First Trust Nasdaq Cybersecurity.The report also mentioned four that cover the burgeoning field of robotics: ROBO Global Robotics and Automation Index, Global X Robotics and Artificial Intelligence, First Trust Nasdaq Artificial Intelligence and Robotics, and iShares Robotics and Artificial Intelligence.The performance of many of them last year illustrates the perils of owning an idea that would seem to have a lot of promise but so far has not delivered on it. The S&amp;P 500 fell 6.2 percent last year, and the Nasdaq Composite Index, a benchmark for technology stocks, lost 3.9 percent. The ETFMG gaming fund lagged both indexes badly, losing 18.8 percent, while the VanEck gaming fund was down 12.6 percent just since its introduction in mid-October.The cybersecurity funds did much better. ETFMG Prime Security rose 6.5 percent in 2018, and the First Trust fund eked out a 1.3 percent gain.As for the robotics portfolios, their returns have been awful. None of the four came close to matching the Nasdaq index. Losses last year ranged between 14 percent and 29 percent.Because interest in these areas tends to come and go, Mr. Browne uses thematic E.T.F.s to carry out short-term asset allocation decisions. Haim Israel, head of thematic investing at Bank of America Merrill Lynch, by contrast, views several technologies covered by the E.T.F.s as long-term opportunities.The business and investment prospects associated with themes like Big Data, artificial intelligence, privacy and cyberthreats, the report said, will be helped by a “techceleration” resulting from the introduction of so-called 5G technology featuring much faster data transmission rates. The rollout of 5G “will bring about the fastest transformation in human history,” Mr. Israel predicted. The reduced time it will take to transmit data will help the spread of all sorts of technologies, like gaming or self-driving cars, he said.Mr. Israel’s analysis and outlook are plausible — for the world as it is today and for various technologies as they have developed so far. As for five years from now, who knows? Change, often radical and unforeseeable, is a hallmark of the sector, making most forecasts speculative at best. That is one of the main complaints that investment advisers have with thematic E.T.F.s.“We’ve been around long enough to see a lot of the ‘next big thing,’ said Leon LaBrecque, chief executive of LJPR Financial Advisors in Troy, Mich. “Remember Blockbuster or Boston Chicken? Anyone remember the first search engine? New tech becomes old tech.”For investors interested in taking a shot with thematic E.T.F.s, advisers suggest using risk capital, and then only small amounts of it.Mr. Masucci views thematic E.T.F.s as superior alternatives to buying individual stocks. These E.T.F.s “are a tax efficient, liquid, transparent way to give that exposure without relying on advisers’ ability to pick stocks,” he said.But Mr. Cordaro pointed to a conundrum that anyone contemplating investing in thematic E.T.F.s faces: “Because they can be riskier, you wouldn’t want them to be too much of your portfolio,” no more than 5 percent, he said. “The paradox is that’s not going to move the needle that much. You’re not going to make much money on it.”If you still want to try to move the needle, he advises doing it with funds that emphasize smaller, younger businesses that are pure plays in a particular niche and that don’t fill their portfolios with established companies that only dabble in fledgling technology.Mr. Rosenbluth noted in his report, for instance, that the VanEck and ETFMG gaming funds both hold the gaming stocks Activision and Electronic Arts, but only the ETFMG fund owns the larger, more diversified tech stocks Apple and Microsoft. By contrast, the ETFMG cybersecurity portfolio is more skewed toward smaller software companies than First Trust Nasdaq Cybersecurity, while the latter holds more in big defense companies like Raytheon than the ETFMG fund does.As for the robotics funds, the two with portfolios published on third-party sites like Morningstar’s, ROBO Global Robotics and Global X Robotics, each own big companies like Nvidia and Intuitive Surgical, and smaller ones like Helix Energy Solutions.In the end, the most effective way to invest in the next big thing may be to avoid trying to do it through thematic E.T.F.s at all.“Why even go for that ride is the question,” Mr. Browne said. When you own a diversified fund, “whatever drives the economy is going to be in your portfolio. It doesn’t rely on your or my predictions of what that’s going to be.”Mr. LaBrecque recommended a similarly broad, simple approach.“We can buy the S&amp;P 500 and get the new FANGs,” a reference to Facebook, Amazon, Netflix and Google, “and the next acronym of choice,” he said. “And we can get the companies that make all the stuff people buy on Amazon, and the cars people drive to the store to buy the food to eat while they watch Netflix. And when the next thing comes along, we can own that, as well.”

Supported byBy Jane L. LevereTravel companies were hit by one data breach after another last year — firms including Marriott, British Airways, Delta Air Lines and the travel booking site Orbitz.Marriott estimates that as a result of its breach — in which the reservation database of Starwood-branded hotels in its portfolio was hacked — 383 million guest records could have been affected and 5.25 million unencrypted passport numbers were possibly compromised. And experts expect breaches in the travel sector will continue.“Travel companies are a prime target of cyberthefts” because they have “highly sensitive, personally identifiable information,” said Eva Velasquez, chief executive of the Identity Theft Resource Center, a national nonprofit organization in San Diego that supports victims of identity theft and seeks to broaden public awareness.But travelers do have options to protect their information.Bruce McIndoe, president of WorldAware, a risk management company, recommends creating a “digital persona” when booking travel or making other online transactions. This can include setting up a new, disposable phone number using a service like Google Voice and RingCentral to screen any calls based on caller ID, and to forward these to the phone number that you want to protect.Mr. McIndoe also suggests creating what he calls a throwaway email address, to be used only when booking online, to protect your actual personal or work email from theft. You can also keep your home and work addresses private with a service like iPostal1.com, PhysicalAddress.com and PostScanMail.com, which can create a new mailing address for you. And you can rent a post office box from the United States Postal Service, though this cannot be used for many online transactions.There are many steps you can take to protect any device you bring on business trips. If you work for a large company or service provider, like a law or accounting firm, your employer may be able to provide clean devices, even some with special protections appropriate for whatever destination you visit.Before leaving on a trip, Sam Rubin, a vice president of the Crypsis Group, a cybersecurity consulting firm, advises all travelers, regardless of the size of their employer, to make sure their laptops are encrypted, via software like BitLocker for Windows laptops or Filevault, for Macs. He also suggests backing up data regularly, installing application updates and deleting unneeded and old data from devices.The Global Business Travel Association, a trade group for corporate travel managers, suggests using a privacy filter on your laptop and tablet screen when you’re traveling. To prevent theft, lock your devices when you’re not using them, through a PIN, password protection or physical locks and alarms. The group also recommends using a juice-jack protector — attached to the end of your USB cord — to protect against data skimmers when you plug the cord into a public charging station. If you bring your own charging device, you won’t need a public charger.Experts strongly recommend not connecting to unsecured public Wi-Fi systems anywhere in the world, not only at coffee shops like Starbucks but also in airports and hotels, among other places. If you must use these, Si-Yeon Kim, chief risk and compliance officer of American Express Global Business Travel, suggests minimizing the number of documents you open, and being careful of whatever information you transmit.Christel Cao-Delebarre, the global privacy officer in London for Carlson Wagonlit Travel, a travel management company, advises being “very careful about speaking with colleagues and possibly sharing confidential information in public places.” She also urges travelers not to leave confidential documents unattended either in conference or guest rooms at hotels and elsewhere.When it comes to working online, Mr. Rubin advises using two-factor authentication on all Internet-accessible accounts. He suggests locking and password-protecting your mobile phone and configuring it to automatically lock after a period of inactivity, and using secure passwords, with a different password for each device and account. Password managers like LastPass and Keeper can help you remember and manage these.As for making purchases online, consider signing up for a credit card to be used only for such transactions. You also can set up a virtual credit card for a one-time purchase whose cost you can limit. Some of these can also be used to pay for recurring charges; those amounts can also be limited. Virtual credit cards are issued by companies such as Bank of America, Citi, Capital One, American Express and Privacy.com. According to Mr. Rubin, if the virtual credit card is compromised, it should have no impact on your physical card.Another payment option, possibly more secure than credit cards, is PayPal, said Robert Austin, president of KoreLogic, a cybersecurity company.BCD Travel, another travel management company, advises against posting pictures online of your itineraries, tickets or boarding passes. It also urges travelers to never leave their boarding passes and tickets on an airplane or in a hotel room, and to shred these once you’ve used them, all steps to keep cyberthieves from obtaining your travel details. Another protective measure is to use digital boarding passes issued by the airline, and apps like BCD’s TripSource, TripLingo, Apple Wallet and Google Pay. This information will be protected by the security code on your mobile phone even if the phone is lost or stolen.John Reed Stark, former chief of the S.E.C.’s Office of Internet Enforcement and author of “The Cybersecurity Due Diligence Handbook,” advises setting up your credit card account to automatically notify you of all transactions via email or its app, which he said will make you aware of every transaction as it occurs. He also suggests setting up a separate email account for these alerts, so you can easily track them and not clog up other accounts.To further track any suspicious activity, he advises subscribing to a credit and identity monitoring company — such as Experian, TransUnion or Equifax — that can provide alerts relating to your credit rating, credit cards and banking.For additional protection, Mr. Rubin suggests the purchase of an individual cybersecurity insurance policy, offered by companies like Chubb and NAS Insurance. Although such policies have long existed for businesses, individual policies are a new development.Henry Harteveldt, president of Atmosphere Research Group, a travel research company, said his company had found that a growing number of travelers were becoming uncomfortable with sharing their personal information with travel sellers.“The lesson for travel suppliers here is that no matter how good they think their cybersecurity hardware and software practices are, they may never be good enough,” Mr. Harteveldt said. “Sadly, there will be one hacker a step ahead at some travel company.”

Supported byBitsBy Nicole PerlrothEach week, technology reporters and columnists from The New York Times review the week’s news, offering analysis and maybe a joke or two about the most important developments in the tech industry. Want this newsletter in your inbox? Sign up here.Hello, dear readers! I’m Nicole Perlroth, cybersecurity reporter here at The Times. I’m afraid the week’s news isn’t all unicorns and rainbows.This should come as a shock to no one, but President Trump’s confrontational diplomacy has energized state hackers in Iran and China. They are targeting companies and government agencies in the United States with renewed gusto, after a multiyear lull. The rebound in activity comes on top of the continuing threat from Russians, who have already started hacking European civil society groups before elections there in May.Consider this a preview of 2020.With the United States pulling out of the nuclear deal with Iran, Iranian hackers are hitting American banks, businesses and federal agencies with cyberattacks. They’ve significantly stepped up their game: harder to track down and more effective.We’re no longer talking so-called denial-of-service attacks that make websites hiccup. They’re exploiting weaknesses in the internet’s backbone to steal web traffic as it passes between government agencies, banks and businesses that manage their back-end infrastructure.The attacks rattled Homeland Security officials, who triggered an emergency alert during the government shutdown last month. Security researchers say that the attacks have not relented and that they’re hitting American targets with an unnerving success rate.The news out of China is even more troubling. Mr. Trump’s trade confrontations with Beijing have energized state hackers in Beijing, who have renewed attacks on American businesses, especially in high-tech and defense companies.Chinese industrial espionage notably dropped after President Barack Obama and President Xi Jinping of China reached a 2015 deal to cease cybertheft of trade secrets. Now, the gloves are off.Miriam Wugmeister, a cybersecurity specialist at the law firm Morrison Foerster, told me that Fortune 500 companies were being hit at “shockingly high” rates.It’s rare that victims step forward — state laws require companies to disclose breaches only if personal data is compromised — but T-Mobile, Boeing and General Electric Aviation are among the companies in the crossfire.If that’s not worrying you, consider my colleague Sui-Lee Wee’s blockbuster report Thursday on China’s campaign to build a DNA database, in part to track and suppress China’s minority Uighur population. Beijing could not have pulled this off without a big helping hand from Thermo Fisher, a Massachusetts equipment maker, and genetic material provided by a prominent Yale University researcher who says he was unaware the material was used as a surveillance tool.In other news:■ Lyft is racing to beat Uber to an initial public offering, my colleagues Mike Isaac and Kate Conger reported. Lyft is hoping to debut on the Nasdaq at a $20 billion to $25 billion valuation before it’s overshadowed by its bigger ride-hailing competitor, Uber, which bankers initially pegged at a $120 billion valuation.■ Google is losing advertisers after a YouTuber posted video showing the prevalence of pedophiles who comment on videos of children doing regular activities like gymnastics or stretching. My colleagues Dai Wakabayashi and Sapna Maheshwari reported that major brands like Nestlé and Epic Games have pulled advertising after users flagged their ads on children’s videos targeted by pedophiles.YouTube and other big tech companies are already under fire for failing to aggressively police their platforms. Last month, YouTube said it had tweaked its algorithm to stop recommending conspiracy theories to users. This past week, my colleague Kevin Roose wrote a terrific piece outlining one of the central challenges for the company: Some of YouTube’s biggest stars (and ad magnets) push conspiracies.Google is hardly the only company struggling with misinformation. This month, The Guardian discovered that YouTube’s recommendation algorithms and Facebook’s search results were still steering viewers from fact-based medical information to anti-vaccine misinformation. All this as the Pacific Northwest is still reeling from an emergency measles outbreak.■ Karl Lagerfeld, the fashion icon, died in Paris on Tuesday. True to form, no obituary had an accurate read on his age, though The Times noted he was “generally thought to be 85.”A tech newsletter this depressing would not be complete without my favorite Lagerfeld quote: “Sweatpants are a sign of defeat. You lost control of your life, so you bought some sweatpants.” (Thank God Karl Lagerfeld never set foot in Silicon Valley.)Nicole Perlroth writes about cybersecurity in the Times’s San Francisco bureau. Follow her here on Twitter: @nicoleperlroth.

Supported byBy Paul MozurHONG KONG — It has been a tough year in China for America’s technology companies.Uber sold off its operations there. Beijing ordered some of Apple’s services shuttered. And Microsoft faced a new inquiry.Now, in the final days of 2016, China’s internet regulator suggested the coming year may be even trickier. A report by the regulator on Tuesday suggested it would formalize a cybersecurity review system on tech products in the country.That could mean another problematic step for foreign tech firms in what has already become a tough market. The report did not offer details about what the government checks would look for, but the language was similar to that described in an article in The New York Times in May about foreign companies quietly submitting to security checks targeting encryption and data storage.Over the course of 2016 and part of 2015, a number of major foreign technology companies were subject to secretive Chinese security reviews. During the checks, Chinese officials would ask employees of the companies to answer questions about products in person. The reviews are run by a committee of engineers and experts with ties to the country’s military and security agencies.The checks have already raised alarms among American tech companies, and if formalized, they could create a new standoff between China and the United States over internet policy.The report, the first of its kind released by the regulator, the Cyberspace Administration of China, is part of a broader effort to streamline cybersecurity management in the country. More broadly, it outlined other details of efforts to enhance already unprecedented internet controls in China. For example, the report also doubles down on a cybersecurity law passed last month that raised concerns among human rights groups and foreign companies.Beijing has struggled to balance its goal of fostering innovation with its desire to keep control over a communication medium it believes could be destabilizing. While it includes boilerplate references to opening up, the report makes clear that the government will continue to err on the side of control for now.In a section subtitled “Peace,” the report said that Beijing would work to get ahead of a global cybersecurity arms race threatening international peace. In another part, the regulator said that China would use military means if necessary to protect its internet sovereignty. China has said in the past that the internet represents a new realm, akin to space, in which it must assert its rulership rights.The new report is the clearest signal yet of the government’s intent to crystallize those checks into a formal policy.The document includes a long list of economic sectors that could be deemed sensitive, which could mean that they would eventually be required to use only computing equipment approved by regulators. The sectors include energy, finance, traffic, education, research, industry, water management, manufacturing and health care, as well as communications systems and the internet.To some degree, bringing the checks into the open would be welcome. Some people who were aware of the security checks on encryption and data storage complained that they were vaguely defined and treated as a secret. For foreign companies, that left open the possibility that the checks could be used to extract trade secrets or to find weaknesses in products for state hackers.Still, if China were to be more public about the checks, it could lead to copycat policies from other countries, analysts have said.Drafts of proposed Chinese laws are typically released to domestic and foreign companies for comment. In this case, the reviews were carried out without formal legislative process, meaning that companies had little room to push back.Cao Li in Beijing contributed research.

Supported byletterA reader suggests that some of the good guys may in fact be bad guys when it serves their purpose.To the Editor:“Avoiding Hacking Stereotypes”  (Inside The Times, Sept. 24), like other reporting on the subject, classifies hackers into two groups: the “good” guys and the “bad” guys. The good guys, the cybersecurity professionals, some of whom are former bad guys, work for companies and organizations to bolster defenses against the bad guys, who hack with nefarious intent. But how can we know that these respected and lauded good guys are always good? Human nature being what it is, some of the good guys may not always be immune to the pressures and greed that may result in working a cybersecurity gig by day and operating illicitly at night.The public and the companies that have critical information on their computers and devices always need to be vigilant and on guard even if they employ cybersecurity experts.Robert GordonHouston

Supported byBy Zolan Kanno-YoungsWASHINGTON — Kirstjen Nielsen, the homeland security secretary, said on Monday that cyberthreats against the United States were a national security crisis that she described as her top priority — not the situation for which President Trump last month declared a national emergency.“On top of my list of threats, that many of you can guess, the word ‘cyber’ is circled, highlighted and underlined,” Ms. Nielsen said in a speech outlining her department’s focus in the coming year. “The cyberdomain is a target, a weapon and a threat vector all at the same time.”Mr. Trump has called the increasing flow of immigrants to the southern border one of the most urgent national security issues threatening the United States. Last week, issuing his first veto against legislation that would have blocked him from diverting Defense Department funds to build a border wall, the president described a recent spike in migrants crossing the border as an “invasion.”The Department of Homeland Security oversees customs officers and immigration agents who are on the front lines of the Trump administration’s campaign to close the border to illegal immigration.Ms. Nielsen did dedicate a portion of her speech on Monday to what she called a “humanitarian and security catastrophe” of Central American families traveling to the border. She also noted that the projected number of migrants who may be apprehended at the southern border this month was expected to rise to 100,000, up from 76,000 in February.But mentions of digital threats were dispersed throughout her approximately 35-minute address to an auditorium of various Department of Homeland Security officials.Among global jihadists and transnational criminals, Ms. Nielsen listed “cyberthugs and hackers and resurgent nation-state rivals” as an emerging threat to the United States. She asked two cybersecurity officials who helped safeguard the 2018 elections to stand for a round of applause.Ms. Nielsen also assailed President Vladimir V. Putin of Russia and the Kremlin “for a concerted effort to undermine our elections and our democratic process using cyberenabled means.” And she said the average American citizen or company was “no match” for virtual threats from Russia, China, North Korea and Iran.“I am more worried about the ability of bad guys to hijack our networks than their ability to hijack our flights,” Ms. Nielsen said. “I am concerned about them holding our infrastructure hostage, stealing our money and secrets, exploiting children online and even hacking our democracy.”John Cohen, a former acting under secretary for intelligence during the Obama administration, said law enforcement could no longer look at the threats in the digital world and the physical world as separate issues. Extremist groups now circulate videos on the internet to inspire terrorist attacks, and drug traffickers are using the dark web — something Ms. Nielsen also highlighted in her speech.Mr. Cohen said he remained unclear on how Ms. Nielsen proposed combating cybersecurity threats.“There is an incredible amount of talent at D.H.S.,” said Mr. Cohen, also a senior adviser at the agency during the George W. Bush administration. “My concern is that talent and those capabilities are being underutilized, because in the eyes of many at the White House, the sole purpose for D.H.S. is to conduct its immigrant and border security activities.”Ms. Nielsen said the department was focused on increasing collaboration with the private sector, citing a summit meeting held in New York last year for industry and government officials. She said she expected the cooperation between various homeland security agencies to improve when the department consolidates at a former mental hospital next month.She praised the department’s work in defending the integrity of the 2018 midterm elections and said she was confident in her department’s ability to secure the 2020 presidential vote. Ms. Nielsen also said homeland security would continue to pursue prosecutions against foreign entities that hack the American digital infrastructure.“What worries me, though, is not what these threat actors have done,” Ms. Nielsen said, “but what they have the capability to do.”

Supported byTech FixBy Brian X. ChenSAN FRANCISCO — Facebook said on Thursday that millions of user account passwords had been stored insecurely, potentially allowing employees to gain access to people’s accounts without their knowledge.The Silicon Valley company publicized the security failure around the same time that Brian Krebs, a cybersecurity writer, reported the password vulnerability. Mr. Krebs said an audit by Facebook had found that hundreds of millions of user passwords dating to 2012 were stored in a format known as plain text, which makes the passwords readable to more than 20,000 of the company’s employees.Facebook said that it had found no evidence of abuse and that it would begin alerting millions of its users and thousands of Instagram users about the issue. The company said it would not require people to reset their passwords.The security failure is another embarrassment for Facebook, a $470 billion colossus that employs some of the most sought-after cybersecurity experts in the industry. It adds to a growing list of data scandals that have tarnished Facebook’s reputation over the last few years. Last year, amid revelations that a political consulting firm improperly gained access to the data of millions, Facebook also revealed that an attack on its network had exposed the personal information of tens of millions of users.In response, the company has repeatedly said it plans to improve how it safeguards people’s data.“There is nothing more important to us than protecting people’s information, and we will continue making improvements as part of our ongoing security efforts at Facebook,” Pedro Canahuati, Facebook’s vice president of engineering in security and privacy, said in a blog post on Thursday.Here’s a rundown of what you need to know about the password vulnerability and what you can do.Storing passwords in plain text is a poor security practice. It leaves passwords wide open to cyberattacks or potential employee abuse. A better security practice would have been to keep the passwords in a scrambled format that is indecipherable.Facebook said it had not found evidence of abuse, but that does not mean it did not occur. Citing a Facebook insider, Mr. Krebs said access records revealed that 2,000 engineers or developers had made nine million queries for data that included plain-text user passwords.A Facebook employee could have shared your password with someone else who would then have improper access to your account, for instance. Or an employee could have read your password and used it to log on to a different site where you used the same password. There are plenty of possibilities.Ultimately, a company as large, rich and well staffed as Facebook should have known better.There’s no easy way to know. Facebook is still investigating, and will begin alerting people who might have had their passwords stored in the plain text format.Facebook is not requiring users to change their passwords, but you should do it anyway.There are many methods for setting strong passwords — for example, do not use the same password across multiple sites, and do not use your Social Security number as a username or a password. You can set up security features such as two-step verification as well.There are a few other steps to take. I recommend also setting up your Facebook account to receive alerts in the event that an unrecognized device logs in to the account. To do so, go to your Facebook app settings, tap Security and Login, and then tap Get alerts about unrecognized logins. From here, you can choose to receive the alerts via messages, email or notifications.An audit of devices that are logged in to your account may also be in order, so that you know what laptops, phones and other gadgets are already accessing your account. On Facebook’s Security and Login page, under the tab labeled “Where You’re Logged In,” you can see a list of devices that are signed in to your account, as well as their locations.If you see an unfamiliar gadget or a device signed in from an odd location, you can click the “Remove” button to boot the device out of your account.Follow Brian X. Chen on Twitter: @bxchen.

Supported byBy Adam SatarianoBARCELONA, Spain — The United Arab Emirates said on Tuesday that it would use equipment from the Chinese technology giant Huawei to build a new high-speed wireless network, despite pressure by the United States to steer clear of the company’s products.The announcement, made at a major European trade conference, was another setback for a campaign by officials from the United States to persuade countries to restrict the use of Huawei equipment in next-generation wireless networks, known as 5G. The Trump administration claims Huawei’s equipment creates a cybersecurity risk that China’s government can exploit for espionage or sabotage, a charge Huawei has forcefully denied.But the plan detailed by the United Arab Emirates’ state-owned telecommunications company, Etisalat, was the latest indication that American officials are having difficulty persuading other countries to go along with their push against Huawei, the world’s largest maker of telecommunications equipment.The United Arab Emirates is a reliable ally of the United States in the Middle East, and a major buyer of American military equipment.Much of the American lobbying campaign against Huawei has focused on Europe, where Huawei sells antennas, base stations and other equipment used in telecommunications networks. Last week, the British authorities signaled that they did not believe a blanket ban of Huawei was necessary to secure the country’s wireless networks. The Czech Republic, France, Germany and Poland are also considering restrictions against Huawei.The United Arab Emirates made its announcement during the annual wireless industry conference, MWC Barcelona. The event, attended by more than 100,000 people from more than 2,000 companies, has become a referendum on Huawei. The United States sent a delegation of officials from the State, Commerce and Defense Departments to meet with representatives from telecommunications companies and governments to warn against using Huawei equipment.On Tuesday, the conference played host to dueling news conferences between Huawei and the United States.In the morning, Huawei’s rotating chairman, Guo Ping, said that the allegations against the company were baseless, and that it would never allow its equipment to be used for spying.“Huawei has not and will never plant back doors,” he said. “And we will never allow anyone to do so in our equipment.”By the afternoon, American officials had called a hastily arranged news conference to reiterate their concerns. Citing a Chinese law that requires companies to work with the government on national security matters, Robert L. Strayer, ambassador for cyber and international communications, said countries should be wary working with Huawei.The confrontation followed a statement last week by Secretary of State Mike Pompeo that countries that allow Huawei in its 5G networks may be blocked from information sharing with the United States.But the threats have failed to win new restrictions against Huawei. A frustration among those who have met with American officials is the lack of evidence indicating how Huawei could present a cybersecurity risk.The United Arab Emirates said Huawei would help build 300 5G towers in the first half of this year. Financial details weren’t disclosed.On Tuesday, Mr. Guo said people were right to be asking about the security of new wireless networks, but added that the United States also deserved scrutiny for its past behavior.“It’s an important question to ask,” he said. “And if you don’t understand this question, go ask Edward Snowden.” Mr. Snowden, a former government contractor, fled the United States in 2013 after revealing a wide-ranging internet surveillance program by American spy agencies and their allies.Follow Adam Satariano on Twitter: @satariano.

Supported byBy Nicole Perlroth and Katie BennerTwo Iranians were behind the ransomware attack that crippled Atlanta’s government for days this year, the Justice Department said in an indictment unsealed on Wednesday, detailing a sophisticated scheme of attacks on hospitals, government agencies and other organizations.The men, Faramarz Shahi Savandi and Mohammad Mehdi Shah Mansouri, chose targets with complex yet vulnerable systems — organizations that could afford to pay ransoms and needed to urgently restore their systems back online, prosecutors said.In the case of Atlanta, one of the most sustained and consequential cyberattacks ever launched against a major American city, the pair broke into the city’s computer systems and held their data hostage for about $51,000 worth of the cryptocurrency Bitcoin, prosecutors said.“They deliberately engaged in an extreme form of 21st-century digital blackmail, attacking and extorting vulnerable victims like hospitals and schools, victims they knew would be willing and able to pay,” Brian Benczkowski, the head of the criminal division of the Justice Department, said in a news conference on Wednesday.The Treasury Department also imposed sanctions on two other Iranians, accusing them of changing the Bitcoin obtained by the hackers into Iranian rial.Mr. Savandi and Mr. Mansouri, who are wanted by the F.B.I., created the malicious software SamSam Ransomware, prosecutors said, and began to gain access to their victims’ computers in January 2016. The software is well known to cybersecurity experts.Atlanta officials said at the time that they would not pay the ransom, even as the attack ground court, parking and employment systems to a halt. For days, police officers wrote reports by hand, warrants were not validated, applications for city jobs sat unprocessed and government workers were unable to access basic administrative systems.“Victims are encouraged not to pay the ransom,” said Amy Hess, a top F.B.I. cybercrime official. She added that there is no guarantee that the victims will get their data back.Mr. Savandi and Mr. Mansouri collected more than $6 million in extortion payments, law enforcement officials said. The cities and businesses targeted lost more than $30 million as they scrambled to fix computer systems and recovered data, according to court documents.Many of the victims were public agencies with missions that involve lifesaving and other critical functions. Among them were Allscripts Healthcare; Laboratory Corporation of America; the city of Newark; the University of Calgary; the Port of San Diego; the Colorado Department of Transportation; and hospitals and health care groups in Los Angeles, Kansas, Maryland and Nebraska.In the case of Mr. Savandi and Mr. Mansouri, the Justice Department indictment indicated that they belonged to the SamSam group, which is well known to cybersecurity researchers.The group was also known for meticulously encrypting its victims’ data, manually from file to file; changing file names to “I’m sorry”; demanding high ransom payments in Bitcoin; and giving victims only a week to pay before they made their data permanently inaccessible, according to major security firms like Symantec, the Crypsis Group and others.Cybersecurity researchers said they were surprised to learn that the SamSam group was based in Iran. Other than the group’s name — Samsam Kandi is the name of a tiny Iranian village — no indicators showed that the group was based in Iran.“They weren’t using any of the Iranian infrastructure or typical Iranian tools and, until now, ransomware was not a typical Iranian attack method,” said Allan Liska, an intelligence analyst at Recorded Future, a threat intelligence firm based in Boston.The defendants had used Bitcoin exchanges to launder their ransomware profits. People in countries with heavily sanctioned governments like North Korea and Iran are increasingly turning to cryptocurrency to bypass sanctions, Mr. Liska said.Though officials were careful to note that the suspects were not affiliated with the government of Iran, American officials and private-sector cybersecurity experts have been closely monitoring internet traffic out of Iran after President Trump’s decision to pull out of the deal over its nuclear program last May.Within 24 hours, monitors in the United States and Israel picked up a notable shift in Iranian state hacking activity, including renewed attacks on diplomats and foreign affairs offices of American allies, as well as employees at major telecommunication companies.

Supported byBy Andrew E. KramerMOSCOW — The treason trial of some of Russia’s top cybersecurity officials ended on Tuesday without solving the mysteries at the center of the case: Why had the men been arrested and what, if anything, did they have to do with Russia’s efforts to disrupt the 2016 American presidential election? Was the prosecution driven not by geopolitical concerns but by a businessman’s desire for revenge?The case began when Russian counterintelligence investigators seized several leading cybersecurity officials in raids conducted in early December 2016. With the arrests coming one month after the American election, speculation swirled that the men had been caught leaking information that helped the F.B.I.’s investigation into Russia’s election hacking.But no clear evidence of that has ever emerged, and the drawn-out trial wrapped up in a Moscow military courtroom without shedding any official light on the reasons for the arrests or if the timing of them, coming so close to the election, signaled a connection to the Russian meddling.Under the watchful eye of security forces wearing ski masks, journalists were allowed into the courtroom for the first time on Tuesday to hear the verdict. Speaking for about 10 minutes, a judge convicted the two main figures and sentenced them to lengthy terms in prison for treason, without saying why.Sergei Mikhailov, a former deputy director of the computer crimes unit of the Federal Security Service, the main successor agency to the K.G.B., was sentenced to 22 years in a penal colony on two counts of treason.Ruslan Stoyanov, a senior researcher at Kaspersky Lab, an antivirus company, was sentenced to 14 years on one count of treason. Two other suspects had earlier pleaded guilty and are awaiting sentencing.Both men convicted Tuesday had for years cooperated with United States law enforcement and Western computer security researchers on bread-and-butter cybercrime issues like stopping spam and bank fraud.But then came the election hacking scandal in 2016, and the men’s arrests signaled that this type of cooperation would stop.Cooperating with the United States was “something that went out of fashion after the scandal,” said Andrei Soldatov, the author of “The Red Web,” and an authority on Russian internet policies.As part of the election interference operation, two Russian hacking groups intruded into the servers of the Democratic National Committee. One group was affiliated with the F.S.B., Mr. Mikhailov’s agency, and the other with the Russian military intelligence organization known as the G.R.U., according to United States government officials and cybersecurity researchers who studied the breach.Only the G.R.U. leaked the stolen information, according to a United States interagency report on the hacking released in 2017. The special counsel investigating Russian meddling, Robert S. Mueller III, last year indicted 12 G.R.U. officers.The detailed accusations by American intelligence agencies against Russia, and the stated high level of confidence in their findings, gave rise to questions about whether they had sources inside Russia.Leaks about the treason case reported in the Russian news media, as well as interviews with defense lawyers and a witness, have indicated that the defendants’ ties to American officials long predated the presidential campaign, and that the information they passed on was not directly related to the hacking investigation.Kommersant, a Russian newspaper, reported this month that Mr. Mikhailov and Mr. Stoyanov were accused of revealing to the F.B.I. information about F.S.B. investigative methods while cooperating with American colleagues on a criminal case nearly a decade ago.Mr. Mikhailov, through intermediaries, passed the data to the F.B.I. in 2011 while investigating ChronoPay, a Russian online payments processing company, the newspaper report said, potentially opening a window on money flows in the Russian online underworld — information that could also be useful in the investigation of the election hacking.At the time, Russia was under diplomatic pressure from the United States and Canada to prosecute the company’s owner, Pavel Vrublevsky, for selling counterfeit erectile dysfunction pills to Americans through websites. Mr. Vrublevsky has denied ties to that scheme.Mr. Mikhailov led the successful prosecution of Mr. Vrublevsky on a separate accusation of hacking the payment system for online ticket sales at Aeroflot, the Russian national airline.Outside the courtroom on Tuesday, a defense lawyer, Inga Lebedeva, told reporters that Mr. Vrublevsky had initiated the treason case in a vendetta against the F.S.B. official and the cybercrime researcher who had put him in prison in the Aeroflot case.“His goal was revenge,” Ms. Lebedeva said. At no point during the closed trial, she said, had Russian meddling in the 2016 United States election come up.“The boys think that in their activities against hackers and criminals they stepped on somebody’s tail,” Ms. Lebedeva said of the two defendants. She said both men would appeal their convictions.Mr. Vrublevsky, in an interview, said he had testified against the pair in the treason trial and believed that they had indeed illegally passed information to the American authorities, but not about election hacking. “These guys were selling fairy tales to the United States about people doing business, like me,” he said.Still, the arrests amounted to a purge of the leadership of the cyberwing of Russia’s main intelligence agency in the midst of the electoral hacking scandal, an issue carrying immense implications for Russia’s relations with the United States.Along with Mr. Mikhailov, who was reportedly dragged from an F.S.B. meeting with a bag over his head, Russian counterintelligence officers detained his deputy, Dmitry A. Dokuchaev. Mr. Dokuchaev pleaded guilty in the treason case.The United States has not accused Mr. Dokuchaev of having any role in the election hacking but has indicted him in a separate cybercrime case that overlaps with sanctions imposed on Russians for election meddling. Federal authorities in Washington and San Francisco in 2017 accused Mr. Dokuchaev, who at the time was also facing the treason charge in Russia, of doubling as a cybercriminal while working at the F.S.B. He was accused of hacking Yahoo and stealing 500 million passwords.That indictment identified him as having overseen the work of one of three others named in the Yahoo hack, a suspected cybercriminal, Aleksei A. Belan, whom the Obama administration placed under sanctions in relation to the election hacking.

Supported byBy Melissa EddyBERLIN — After hackers, later determined to be working for Russia, broke into Parliament’s main computer network three years ago, the government vowed to fortify its cybersecurity. The authorities schooled lawmakers about changing passwords, using two-step identification and other measures to protect online data.But on Friday, nearly 1,000 lawmakers and other prominent Germans, including rappers, journalists and internet personalities, awoke to find links to their street and email addresses, private chats from social media, bank account details and pictures of their children published on Twitter, in another major breach aimed at the country’s political establishment.All those attacked had a history of criticizing the far right, whose politicians appeared to be spared, raising suspicion that the hacker or hackers were sympathetic to their agenda, though the authorities said they had no indication yet who was behind the attack.The breach spread a fresh round of alarm in Germany, a country where citizens especially covet their privacy, and once again raised the disconcerting question of whether even the most vigilant and sophisticated individuals and governments can safeguard their computers and the valuable personal, financial and other sensitive information that resides there.Even beyond Germany, the attack fit into a building pattern of breaches with the seeming aim of shaking confidence in the political establishment or undermining important players in it.The weaponization of hacked information has become an increasingly common theme in politics, said Jonas Kaiser, a Harvard University expert who studies online misinformation.“A lot of leaks and hacking campaigns have become a more normal part of the political discourse,” he said.The most notable examples were emails from the Democratic National Committee that were stolen during the 2016 election in the United States and have become part of the investigation into whether Russia sought to tilt the vote in President Trump’s favor. On the eve of voting in France’s 2017 elections, hackers similarly made a public dump of what was presumed to be a mix of real and fake emails from the campaign of Emmanuel Macron, now the president.This time, the leaks went on for more than a month as the hackers teased and dribbled out their bounty. It was only late Thursday, when the Twitter account of a popular German YouTuber, Simon Unge, who has some two million followers, was hijacked that the extent of the attacks finally came into fuller light.Mr. Kaiser said the authorities would try to determine whether the attack was perpetrated by a state-backed group. The release of personal information by an individual or small group would generate a different response than one done by a government, he said.Cybersecurity experts said the hacker or hackers appeared to have taken considerable effort to collect and spread the looted information across different servers in an attempt to make tracing them and taking down the data more difficult.Angela Merkel’s government vowed a thorough investigation. “The German government takes this incident very seriously,” said Martina Fietz, a spokeswoman for the chancellor.As the country’s main cybersecurity defense team called a crisis meeting to coordinate with domestic and foreign intelligence agencies early Friday, Twitter took down the accounts used by a hacker calling himself GOd that had been broadcasting links to the information since early last month.The hacker released the information through links published on Twitter in the form of an Advent calendar, where a window is opened every day leading up to Christmas, revealing a picture or treat.“The first window is for a very special beloved moderator who everyone knows,” read the entry for Dec. 1, which included links to private information from the comedian Jan Böhmermann, who several months ago had started an initiative to discredit a group of far-right internet trolls.Starting on Dec. 20, Germany’s established political parties appeared, beginning with the Free Democrats and followed by the Left, the Greens and Social Democrats.Dec. 24 — the final day in the calendar — was reserved for the conservative Christian Democrats and Christian Social Union. The published link led to servers hosting lists of personal information ranging from internal party documents to screen shots of private chat exchanges to images of a personal ID card, front and back.Only the main opposition force in Parliament, the far-right Alternative for Germany, or AfD, was excluded. Stephan Brandner, a member of Parliament with the party responsible for justice affairs, condemned the hack. “Protection of private data goes for everyone, including politicians, regardless of which party they belong to,” he said.Germans prize personal privacy — a legacy of abuses by the Nazi- and Communist-era secret police — and the country has long had some of the world’s strictest laws protecting personal information. Germany was the first country to force Google to allow individuals to blur images of their homes on its Street View mapping service, following outrage over the amount of data the company was collecting.But German defenses have not caught up to German fears, rendering the country exceedingly vulnerable to attacks.Although the Twitter accounts used for disseminating the information were taken down early Friday, several hours later, many of the servers hosting the information remained accessible.Lukasz Olejnik, an independent cybersecurity and privacy adviser, said the attack showed deliberate planning. Dispersing the content among servers across the internet made it more likely the information would remain accessible even after Twitter shut down the account that initially published the links, he said.“The attacker’s intent is not clear at this moment but it is clear that a considerable effort was put in,” said Mr. Olejnik, who is also a research associate at the Center for Technology and Global Affairs at Oxford University. “It was work intensive.”Germany’s cybersecurity office said it was investigating whether the data was harvested in a central attack, a series of separate ones originating from different services, or in private communications.“At this time, there is no indication that the government network was breached,” the office, known by its German initials B.S.I., said in a statement.Beyond Germany, the hacking adds to concerns about the security of European parliamentary elections in May, which many officials fear are vulnerable to digital interference and disinformation campaigns by hackers or state-backed groups. Last month, European Union officials announced a plan to better coordinate responses to false messages around the elections.Leading members of the Greens and the Social Democrats said they filed criminal charges against unknown individuals for illegally publishing their personal data. A spokesman for the Left party confirmed that the information of some of its members had been exposed, including that of Dietmar Bartsch, the leader of its caucus in the lower house of Parliament.Mr. Böhmermann, the first person targeted in the leak, tried several months ago to organize opposition to the far-right group Reconquista Germanica, which spreads disinformation and harasses, provokes and belittles opponents.The data, which included Mr. Böhmermann’s phone numbers, personal chats and photographs of his two young sons, was advertised as, “Nice things that you can have fun with.”Germany’s main government network was breached by hackers in 2015, and the authorities worried that information obtained then would be used against politicians leading up to the 2017 election. Those fears were largely unfounded.Hackers appeared to have again penetrated the German government’s main data network last March — a system that was supposed to be particularly secure and is used by the chancellor’s office, ministries and Parliament.Luca Hammer, an independent German social media analyst who studies activity on Twitter, said that because no right-wing troll chat groups had picked up the leak, the hacker may have been a single individual.“They had to get into a popular Twitter account to get noticed,” he said over Twitter. “Therefore I assume they acted alone. But I don’t know.”The attack prompted warnings in German media about the need for greater vigilance by the government and of how individuals can better protect themselves online.A commentary in Süddeutsche Zeitung drew a parallel between the cyberattack and terrorism. “Even if in this case nobody has been injured or killed,” the aim of the hack was to trigger “a diffuse fear” in German society at large.“The question of whether public spaces are safe for the individual turns out to be the same for Facebook and the Outlook mailbox as it is for soccer stadiums and the Oktoberfest,” the paper wrote.Adam Satariano contributed reporting from London.Follow Melissa Eddy on Twitter: @meddynyt.

