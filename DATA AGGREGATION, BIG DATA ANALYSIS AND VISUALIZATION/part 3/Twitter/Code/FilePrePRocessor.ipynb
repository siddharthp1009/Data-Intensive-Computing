{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/siddharthpandey/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlNEW9.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlFinal.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlNEW.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlFinal2.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlFinal3.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlFinal1.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlFinal4.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlNEW10.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlNEW11.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlNEW12.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlNEW7.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawl5.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlNEW6.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlNEW4.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlNEW5.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlNEW2.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/cc/rawdata/commoncrawlNEW3.txt\n",
      "*********** FILE WRITE COMPLETE ***************\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import nltk \n",
    "nltk.download('wordnet')\n",
    "import glob\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "\n",
    "def chec(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "path = \"/DRIVE PATH HERE/*.txt\" #note C:\n",
    "path\n",
    "files = glob.glob(path)\n",
    "\n",
    "for name in files:\n",
    "    print(name)\n",
    "    reader = open(name,'r')\n",
    "    for data in reader:\n",
    "        finalString = \"\"\n",
    "        punctuations = '''!()-[]{};:'’\"\\,.,”“.“‘<>—./?@#$%^&*_~'''\n",
    "        for character in data:\n",
    "            if(character not in punctuations):\n",
    "                finalString = finalString + character.lower()\n",
    "        stop_words = set(stopwords.words('english')) \n",
    "        word_tokens = word_tokenize(finalString)\n",
    "        filtered_sentence = []\n",
    "        for w in word_tokens: \n",
    "            if w not in stop_words: \n",
    "                filtered_sentence.append(unicode(w, errors='ignore')) \n",
    "        finalStem =[]\n",
    "        porter = PorterStemmer()\n",
    "        lemmatizer = WordNetLemmatizer() \n",
    "        for words in range(0,len(filtered_sentence)):\n",
    "            wrd = lemmatizer.lemmatize(filtered_sentence[words])\n",
    "            finalStem.append(wrd)\n",
    "        name = re.sub('[\\s+]', '', name)\n",
    "        name=name.replace('#','')\n",
    "        file1 = open(name.replace(\"rawdata\",\"FinalData\"), 'a')\n",
    "        for data in (finalStem):\n",
    "            if chec(data.strip())!=True:\n",
    "                if(len(data.strip())>2):\n",
    "                    file1.write(data.encode('utf-8')+' ')\n",
    "        file1.write('\\n\\n')\n",
    "        file1.close()\n",
    "print(\"*********** FILE WRITE COMPLETE ***************\") \n",
    "  #      for line in f:\n",
    "  #          split = line.split()\n",
    "  #          if split:\n",
    "  #              print(line.split())\n",
    "  #  print('\\n\\n\\n')\n",
    "  #  print(name+\" explored\")\n",
    "  #  print(\"ALLOWING SYSTEM TO REST\")\n",
    "  #  time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/tw/tw/FinalData/cybersecurity.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/tw/tw/FinalData/cyber.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/tw/tw/FinalData/hack.txt\n",
      "/Users/siddharthpandey/Desktop/MS/DIC/Lab2/data/tw/tw/FinalData/cybercrime.txt\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
